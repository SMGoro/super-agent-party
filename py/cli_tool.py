#!/usr/bin/env python3
import asyncio
import os
import re
import shutil
import subprocess
import json
import platform
import uuid
import tempfile
import socket
import glob as std_glob
import fnmatch
from pathlib import Path
from typing import AsyncIterator
from datetime import datetime
from collections import deque
import aiofiles
import aiofiles.os
import hashlib
import anyio

# å°è¯•å¯¼å…¥SDKï¼Œå¦‚æœæ˜¯åœ¨ç‹¬ç«‹ç¯å¢ƒè¿è¡Œåˆ™å¿½ç•¥é”™è¯¯
try:
    from claude_agent_sdk import query, ClaudeAgentOptions, AssistantMessage, TextBlock
    from py.get_setting import load_settings
except ImportError:
    print("[WARN] SDK modules not found. Ensure 'claude_agent_sdk' and 'py.get_setting' are available.")
    # Mock load_settings for standalone testing if needed
    async def load_settings():
        return {
            "CLISettings": {"cc_path": os.getcwd()},
            "dsSettings": {},
            "localEnvSettings": {"permissionMode": "yolo"},
            "ccSettings": {"permissionMode": "default"},
            "qcSettings": {"permissionMode": "default"}
        }

# ==================== ç¯å¢ƒåˆå§‹åŒ– ====================

def get_shell_environment():
    """é€šè¿‡å­è¿›ç¨‹è·å–å®Œæ•´çš„ shell ç¯å¢ƒ"""
    shell = os.environ.get('SHELL', '/bin/zsh')
    home = Path.home()
    
    config_commands = [
        f'source {home}/.zshrc && env',
        f'source {home}/.bash_profile && env', 
        f'source {home}/.bashrc && env',
        'env'
    ]
    
    # Windows ç¯å¢ƒç®€å•è·³è¿‡
    if platform.system() == "Windows":
        return

    for cmd in config_commands:
        try:
            result = subprocess.run(
                [shell, '-i', '-c', cmd],
                capture_output=True,
                text=True,
                timeout=5
            )
            if result.returncode == 0:
                for line in result.stdout.splitlines():
                    if '=' in line:
                        var_name, var_value = line.split('=', 1)
                        os.environ[var_name] = var_value
                print("Successfully loaded environment from shell")
                return
        except Exception as e:
            continue
    
    print("Warning: Could not load shell environment, using current environment")

get_shell_environment()

# ==================== æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼šæµå¤„ç† ====================

async def read_stream(stream, *, is_error: bool = False):
    """è¯»å–æµå¹¶æ·»åŠ é”™è¯¯å‰ç¼€"""
    if stream is None:
        return
    async for line in stream:
        prefix = "[ERROR] " if is_error else ""
        yield f"{prefix}{line.decode('utf-8', errors='replace').rstrip()}"

async def _merge_streams(*streams):
    """åˆå¹¶å¤šä¸ªå¼‚æ­¥æµ"""
    streams = [s.__aiter__() for s in streams]
    while streams:
        for stream in list(streams):
            try:
                item = await stream.__anext__()
                yield item
            except StopAsyncIteration:
                streams.remove(stream)

async def _get_current_cwd() -> str:
    """è·å–å½“å‰é…ç½®çš„å·¥ä½œç›®å½•"""
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    if not cwd:
        raise ValueError("No workspace directory specified in settings (CLISettings.cc_path).")
    return cwd

# ==================== [æ–°å¢] æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼šè¿›ç¨‹ç®¡ç† ====================

class ProcessManager:
    """å…¨å±€åå°è¿›ç¨‹ç®¡ç†å™¨ (Docker & Local) - å¢å¼ºç‰ˆ (æ”¯æŒ Windows è¿›ç¨‹æ ‘æŸ¥æ€)"""
    def __init__(self):
        # ç»“æ„: {pid: {"proc": proc, "logs": deque, "cmd": str, "type": str, "task": task, "status": str, "start_time": str}}
        self._processes = {}
        self._counter = 0

    def generate_id(self):
        self._counter += 1
        return str(self._counter)

    async def register_process(self, proc, cmd: str, p_type: str):
        """æ³¨å†Œå¹¶å¼€å§‹ç›‘æ§ä¸€ä¸ªåå°è¿›ç¨‹"""
        pid = self.generate_id()
        logs = deque(maxlen=2000)
        
        task = asyncio.create_task(self._monitor_output(pid, proc, logs))
        
        self._processes[pid] = {
            "proc": proc,
            "logs": logs,
            "cmd": cmd,
            "type": p_type,
            "task": task,
            "status": "running",
            "start_time": datetime.now().isoformat()
        }
        return pid

    async def _monitor_output(self, pid: str, proc, logs: deque):
        async def read_stream_to_log(stream, prefix=""):
            if not stream: return
            async for line in stream:
                decoded = line.decode('utf-8', errors='replace').rstrip()
                timestamp = datetime.now().strftime("%H:%M:%S")
                logs.append(f"[{timestamp}] {prefix}{decoded}")

        try:
            await asyncio.gather(
                read_stream_to_log(proc.stdout, ""),
                read_stream_to_log(proc.stderr, "[ERR] ")
            )
            await proc.wait()
            if pid in self._processes:
                # åªæœ‰å½“çŠ¶æ€ä¸æ˜¯è¢«æ‰‹åŠ¨ terminated æ—¶æ‰æ›´æ–°ä¸º exited
                if "terminated" not in self._processes[pid]["status"]:
                    self._processes[pid]["status"] = f"exited (code {proc.returncode})"
        except Exception as e:
            if pid in self._processes:
                logs.append(f"[SYSTEM ERROR] Process monitoring failed: {str(e)}")

    def get_logs(self, pid: str, lines: int = 50) -> str:
        if pid not in self._processes:
            return f"Error: Process ID {pid} not found."
        
        entry = self._processes[pid]
        stored_logs = list(entry["logs"])
        subset = stored_logs[-lines:] if lines > 0 else stored_logs
        
        header = f"--- Logs for Process {pid} ({entry['status']}) ---\nCommand: {entry['cmd']}\n"
        return header + "\n".join(subset)

    def list_processes(self):
        if not self._processes:
            return "No background processes running."
        
        result = ["PID | Type   | Status       | Start Time          | Command"]
        result.append("-" * 90)
        
        active_found = False
        for pid, info in list(self._processes.items()):
            cmd_display = (info['cmd'][:45] + '...') if len(info['cmd']) > 45 else info['cmd']
            start_time = info['start_time'].split('T')[-1][:8]
            result.append(f"{pid:<4}| {info['type']:<7}| {info['status']:<13}| {start_time:<20}| {cmd_display}")
            active_found = True
        
        if not active_found:
            return "No background processes running."
        return "\n".join(result)

    async def kill_process(self, pid: str):
        """
        å¼ºåˆ¶ç»“æŸè¿›ç¨‹ã€‚
        é’ˆå¯¹ Windows ä½¿ç”¨ taskkill /T ç»“æŸè¿›ç¨‹æ ‘ï¼Œé˜²æ­¢å­è¿›ç¨‹æ®‹ç•™ã€‚
        """
        if pid not in self._processes:
            return f"Error: Process ID {pid} not found."
        
        info = self._processes[pid]
        proc = info["proc"]
        
        # å³ä½¿ proc.returncode å·²ç»æœ‰å€¼ï¼Œä¹Ÿè¦å°è¯•æ¸…ç†å¯èƒ½çš„å­¤å„¿è¿›ç¨‹
        os_pid = proc.pid
        
        try:
            info["status"] = "terminating..."
            
            if platform.system() == "Windows":
                # Windows: ä½¿ç”¨ taskkill /F (å¼ºåˆ¶) /T (è¿›ç¨‹æ ‘) /PID <pid>
                # è¿™æ˜¯æ¸…ç† PowerShell/CMD å¯åŠ¨çš„å­è¿›ç¨‹çš„å…³é”®
                kill_cmd = f"taskkill /F /T /PID {os_pid}"
                subprocess.run(kill_cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            else:
                # Linux/Mac: å°è¯•æ€è¿›ç¨‹ç»„ (å¦‚æœé€‚ç”¨) æˆ–æ ‡å‡† terminate
                try:
                    proc.terminate()
                    # ç»™ä¸€ç‚¹æ—¶é—´ä¼˜é›…é€€å‡º
                    await asyncio.wait_for(proc.wait(), timeout=2.0)
                except (asyncio.TimeoutError, ProcessLookupError):
                    try:
                        proc.kill()
                    except:
                        pass
            
            info["status"] = "terminated"
            return f"Process {pid} (OS PID {os_pid}) terminated successfully."
            
        except Exception as e:
            return f"Error terminating process {pid}: {str(e)}"
        
process_manager = ProcessManager()

# ==================== [æ–°å¢] æ ¸å¿ƒåŸºç¡€è®¾æ–½ï¼šDocker ç½‘ç»œä»£ç† ====================

class DockerPortProxy:
    """çº¯ Python å®ç°çš„ Docker ç«¯å£è½¬å‘å™¨ (Container -> Host)"""
    def __init__(self, container_name: str):
        self.container_name = container_name
        self.proxies = {} # {local_port: server_obj}

    async def start_forward(self, local_port: int, container_port: int):
        """å¼€å¯è½¬å‘ï¼šæœ¬åœ° TCP Server -> docker exec æ¡¥æ¥ -> å®¹å™¨å†…éƒ¨ç«¯å£"""
        if local_port in self.proxies:
            return f"Port {local_port} is already being forwarded."

        if not self._is_port_available(local_port):
            return f"Error: Local port {local_port} is already in use."

        try:
            server = await asyncio.start_server(
                lambda r, w: self._handle_client(r, w, container_port),
                '127.0.0.1', local_port
            )
            
            self.proxies[local_port] = server
            asyncio.create_task(server.serve_forever())
            return f"Success: Forwarding localhost:{local_port} -> Docker:{container_port}"
        except Exception as e:
            return f"Error starting proxy: {str(e)}"

    def _is_port_available(self, port: int) -> bool:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            return s.connect_ex(('127.0.0.1', port)) != 0

    async def _handle_client(self, client_reader, client_writer, container_port):
        """å¤„ç†æ¯ä¸ªè¿æ¥ï¼šå¯åŠ¨ä¸€ä¸ª docker exec è¿›ç¨‹ä½œä¸ºç®¡é“"""
        try:
            # å¾®å‹ Python è½¬å‘è„šæœ¬ï¼Œåœ¨å®¹å™¨å†…è¿è¡Œ
            proxy_script = (
                "import socket,sys,threading;"
                "s=socket.socket();"
                f"s.connect(('127.0.0.1',{container_port}));"
                "def r():"
                " while True:"
                "  d=s.recv(4096);"
                "  if not d: break;"
                "  sys.stdout.buffer.write(d);sys.stdout.flush();\n"
                "threading.Thread(target=r,daemon=True).start();"
                "while True:"
                " d=sys.stdin.buffer.read(4096);"
                " if not d: break;"
                " s.sendall(d)"
            )

            cmd = [
                "docker", "exec", "-i", 
                self.container_name, 
                "python3", "-u", "-c", proxy_script
            ]

            proc = await asyncio.create_subprocess_exec(
                *cmd,
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.DEVNULL 
            )

            async def pipe_reader_to_writer(reader, writer):
                try:
                    while True:
                        data = await reader.read(4096)
                        if not data: break
                        writer.write(data)
                        await writer.drain()
                except Exception:
                    pass
                finally:
                    try: writer.close()
                    except: pass

            await asyncio.gather(
                pipe_reader_to_writer(client_reader, proc.stdin),  # Local -> Docker
                pipe_reader_to_writer(proc.stdout, client_writer)  # Docker -> Local
            )
            try: proc.terminate()
            except: pass

        except Exception as e:
            try: client_writer.close()
            except: pass

    async def stop_forward(self, local_port: int):
        if local_port in self.proxies:
            server = self.proxies[local_port]
            server.close()
            await server.wait_closed()
            del self.proxies[local_port]
            return f"Stopped forwarding on port {local_port}"
        return f"Port {local_port} was not being forwarded."
    
    def list_proxies(self):
        if not self.proxies:
            return "No active port forwardings."
        return "\n".join([f"localhost:{p} -> container:{p} (active)" for p in self.proxies.keys()])

DOCKER_PROXIES = {} # {container_name: ProxyInstance}

# ==================== Docker Sandbox åŸºç¡€è®¾æ–½ ====================

def get_safe_container_name(cwd: str) -> str:
    """æ ¹æ®è·¯å¾„ç”Ÿæˆåˆæ³•å®¹å™¨å"""
    abs_path = str(Path(cwd).resolve())
    path_hash = hashlib.md5(abs_path.encode()).hexdigest()[:12]
    return f"sandbox-{path_hash}"

async def get_or_create_docker_sandbox(cwd: str, image_name: str = "docker/sandbox-templates:latest") -> str:
    """è·å–æˆ–åˆ›å»ºåŸºäºè·¯å¾„çš„æŒä¹…åŒ–æ²™ç›’"""
    container_name = get_safe_container_name(cwd)
    
    check_proc = await asyncio.create_subprocess_exec(
        "docker", "ps", "-a", "--filter", f"name=^/{container_name}$", "--format", "{{.Names}}|{{.Status}}",
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    stdout, _ = await check_proc.communicate()
    output = stdout.decode().strip()
    
    if container_name in output:
        status = output.split("|")[-1] if "|" in output else ""
        if "Up" in status:
            return container_name
        else:
            await asyncio.create_subprocess_exec("docker", "start", container_name, stdout=asyncio.subprocess.PIPE)
            return container_name
    
    create_cmd = [
        "docker", "run", "-d",
        "--name", container_name,
        "-v", f"{cwd}:/workspace",
        "-w", "/workspace",
        "--restart", "unless-stopped",
        image_name,
        "tail", "-f", "/dev/null"
    ]
    
    proc = await asyncio.create_subprocess_exec(
        *create_cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    stdout, stderr = await proc.communicate()
    
    if proc.returncode == 0:
        return container_name
    else:
        # ç®€å•é‡è¯•é€»è¾‘
        if "is already in use" in stderr.decode():
            await asyncio.sleep(0.5)
            return await get_or_create_docker_sandbox(cwd, image_name)
        raise Exception(f"Failed to create sandbox: {stderr.decode()}")

async def _exec_docker_cmd_simple(cwd: str, cmd_list: list) -> str:
    """å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼šåœ¨å®¹å™¨å†…æ‰§è¡Œç®€å•å‘½ä»¤å¹¶è·å–è¾“å‡º"""
    container_name = await get_or_create_docker_sandbox(cwd)
    full_cmd = ["docker", "exec", "-w", "/workspace", container_name] + cmd_list
    
    proc = await asyncio.create_subprocess_exec(
        *full_cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    stdout, stderr = await proc.communicate()
    
    if proc.returncode != 0:
        raise Exception(f"Command failed: {stderr.decode().strip()}")
    return stdout.decode()

# ==================== Docker ç¯å¢ƒå·¥å…·å®ç° (å«æ–°åŠŸèƒ½) ====================

async def docker_sandbox_async(command: str, background: bool = False) -> str | AsyncIterator[str]:
    """
    [Docker] åœ¨æ²™ç›’ä¸­æ‰§è¡Œå‘½ä»¤
    æ–°å¢å‚æ•°: background (Trueåˆ™åå°è¿è¡Œå¹¶è¿”å›PID)
    """
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    if not cwd: return "Error: No workspace directory specified in settings."
    
    try:
        container_name = await get_or_create_docker_sandbox(cwd)
    except Exception as e:
        return f"Docker Sandbox Error: {str(e)}"

    exec_cmd = [
        "docker", "exec",
        "-i", # ä¿æŒstdinæ‰“å¼€å¯¹æŸäº›äº¤äº’å¼å‘½ä»¤å¾ˆé‡è¦
        container_name,
        "sh", "-c",
        f"cd /workspace && {command}"
    ]
    
    try:
        process = await asyncio.create_subprocess_exec(
            *exec_cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
        )

        # === åå°æ¨¡å¼ ===
        if background:
            pid = await process_manager.register_process(process, f"[Docker] {command}", "docker")
            return f"[SUCCESS] Docker background process started.\nPID: {pid}\nContainer: {container_name}\nUse 'manage_processes' to view logs."

        # === å‰å°æ¨¡å¼ (æµå¼) ===
        async def _stream() -> AsyncIterator[str]:
            output_yielded = False
            async for line in _merge_streams(
                read_stream(process.stdout, is_error=False),
                read_stream(process.stderr, is_error=True),
            ):
                yield line
                output_yielded = True
            
            await process.wait()
            if process.returncode != 0:
                yield f"[EXIT CODE] {process.returncode}"
            elif not output_yielded:
                yield "[SUCCESS] å‘½ä»¤å·²æˆåŠŸæ‰§è¡ŒæœªæŠ¥é”™"
    
        return _stream()
    except Exception as e:
        return f"[ERROR] Execution failed: {str(e)}"

async def edit_file_patch_tool(path: str, old_string: str, new_string: str) -> str:
    """[Docker] ç²¾ç¡®å­—ç¬¦ä¸²æ›¿æ¢"""
    try:
        real_cwd = await _get_current_cwd()
        container_name = await get_or_create_docker_sandbox(real_cwd)
        
        content = await _exec_docker_cmd_simple(real_cwd, ["cat", path])
        
        normalized_content = "\n".join(line.rstrip() for line in content.split("\n"))
        normalized_old = "\n".join(line.rstrip() for line in old_string.split("\n"))
        
        if normalized_old not in normalized_content:
            lines = content.split("\n")
            first_line = old_string.split("\n")[0] if "\n" in old_string else old_string
            similar_lines = [f"Line {i+1}: {line[:80]}" for i, line in enumerate(lines) if first_line.strip() in line]
            error_msg = f"[Error] Old string not found in file '{path}'.\n"
            if similar_lines:
                error_msg += f"\nFound similar lines:\n" + "\n".join(similar_lines[:5])
            return error_msg
        
        new_content = content.replace(old_string, new_string, 1)
        
        with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
            tmp.write(new_content)
            tmp_path = tmp.name
        
        dest_path = f"{container_name}:/workspace/{path}"
        cp_proc = await asyncio.create_subprocess_exec("docker", "cp", tmp_path, dest_path, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        await cp_proc.communicate()
        os.unlink(tmp_path)
        
        if cp_proc.returncode != 0: return "[Error] Patch copy failed."
        return f"[Success] Patched '{path}'."
        
    except Exception as e:
        return f"[Error] Patch failed: {str(e)}"

async def glob_files_tool(pattern: str, exclude: str = "**/node_modules/**,**/.git/**,**/__pycache__/**") -> str:
    """[Docker] Glob é€’å½’æŸ¥æ‰¾"""
    try:
        real_cwd = await _get_current_cwd()
        exclude_list = [e.strip() for e in exclude.split(",") if e.strip()]
        
        python_script = f'''
import glob, os, json, fnmatch
files = glob.glob("/workspace/{pattern}", recursive=True)
exclude_patterns = {exclude_list}
filtered = []
for f in files:
    if not os.path.isfile(f): continue
    rel_path = f.replace("/workspace/", "")
    should_exclude = False
    for ex in exclude_patterns:
        if fnmatch.fnmatch(rel_path, ex) or fnmatch.fnmatch(f, ex):
            should_exclude = True; break
    if not should_exclude: filtered.append(rel_path)
print(json.dumps(filtered))
'''
        output = await _exec_docker_cmd_simple(real_cwd, ["python3", "-c", python_script])
        files = json.loads(output)
        if not files: return "[Result] No files found."
        
        lines = [f"[{len(files)} files matched]"]
        for f in files[:50]:
            icon = "ğŸ" if f.endswith(".py") else "ğŸ“„"
            lines.append(f"{icon} {f}")
        if len(files) > 50: lines.append(f"... {len(files)-50} more")
        return "\n".join(lines)
    except Exception as e:
        return f"[Error] Glob failed: {str(e)}"

async def todo_write_tool(action: str, id: str = None, content: str = None, priority: str = "medium", status: str = None) -> str:
    """[Docker] ä»»åŠ¡ç®¡ç†"""
    try:
        real_cwd = await _get_current_cwd()
        container_name = await get_or_create_docker_sandbox(real_cwd)
        todo_file = "/workspace/.party/ai_todos.json"
        
        try:
            data = await _exec_docker_cmd_simple(real_cwd, ["cat", todo_file])
            todos = json.loads(data)
        except:
            todos = []
            
        if action == "create":
            if not content: return "[Error] Content required."
            new_todo = {
                "id": id or str(uuid.uuid4())[:8],
                "content": content,
                "priority": priority,
                "status": "pending",
                "created_at": datetime.now().isoformat(),
                "completed_at": None  # åˆå§‹åŒ–å®Œæˆæ—¶é—´
            }
            todos.append(new_todo)
            msg = f"[Success] Created {new_todo['id']}"
            
        elif action == "list":
            if not todos: return "No todos."
            lines = ["ğŸ“‹ Tasks:"]
            # æ’åºé€»è¾‘ï¼šæœªå®Œæˆåœ¨å‰ï¼Œé«˜ä¼˜å…ˆçº§åœ¨å‰
            for t in sorted(todos, key=lambda x: (x.get('status') == 'done', x.get('priority') != 'high')):
                icon = "âœ…" if t.get('status') == 'done' else "â³"
                lines.append(f"{icon} [{t['id']}] {t['content'][:40]}")
            return "\n".join(lines)
            
        elif action in ["update", "toggle", "delete"]:
            if not id: return "[Error] ID required."
            target = next((t for t in todos if t['id'] == id), None)
            if not target: return f"ID {id} not found."
            
            if action == "delete":
                todos.remove(target)
                msg = f"Deleted {id}"

            elif action == "toggle":
                # æ ¸å¿ƒé€»è¾‘ï¼šåˆ‡æ¢çŠ¶æ€å¹¶è®°å½•/é‡ç½®å®Œæˆæ—¶é—´
                if target.get('status') != 'done':
                    target['status'] = 'done'
                    target['completed_at'] = datetime.now().isoformat()
                else:
                    target['status'] = 'pending'
                    target['completed_at'] = None
                msg = f"Toggled {id} to {target['status']}"

            elif action == "update":
                if content: target['content'] = content
                if priority: target['priority'] = priority
                
                # æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœ status è¢«æ˜ç¡®ä¿®æ”¹
                if status:
                    if status == "done" and target.get('status') != "done":
                        target['completed_at'] = datetime.now().isoformat()
                    elif status != "done" and target.get('status') == "done":
                        target['completed_at'] = None
                    target['status'] = status
                
                target['updated_at'] = datetime.now().isoformat()
                msg = f"Updated {id}"
        else:
            return "Unknown action."

        # å†™å›é€»è¾‘ (ä¿æŒä¸å˜)
        with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
            tmp.write(json.dumps(todos, indent=2, ensure_ascii=False))
            tmp_path = tmp.name
        
        await _exec_docker_cmd_simple(real_cwd, ["mkdir", "-p", "/workspace/.party"])
        dest = f"{container_name}:{todo_file}"
        proc = await asyncio.create_subprocess_exec("docker", "cp", tmp_path, dest, stdout=asyncio.subprocess.PIPE)
        await proc.wait()
        
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)
            
        return msg
    except Exception as e:
        return f"[Error] Todo failed: {str(e)}"
# æ¢å¤åŸæœ‰çš„ Docker åŸºç¡€æ–‡ä»¶å·¥å…·
async def list_files_tool(path: str = ".", show_all: bool = False) -> str:
    try:
        real_cwd = await _get_current_cwd()
        flag = "-laF" if show_all else "-F"
        return await _exec_docker_cmd_simple(real_cwd, ["ls", flag, path])
    except Exception as e: return str(e)

async def read_file_tool(path: str) -> str:
    try:
        real_cwd = await _get_current_cwd()
        return await _exec_docker_cmd_simple(real_cwd, ["cat", "-n", path])
    except Exception as e: return str(e)

async def edit_file_tool(path: str, content: str) -> str:
    try:
        real_cwd = await _get_current_cwd()
        container_name = await get_or_create_docker_sandbox(real_cwd)
        with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
            tmp.write(content)
            tmp_path = tmp.name
        await _exec_docker_cmd_simple(real_cwd, ["mkdir", "-p", os.path.dirname(path) or "."])
        dest = f"{container_name}:/workspace/{path}"
        proc = await asyncio.create_subprocess_exec("docker", "cp", tmp_path, dest, stdout=asyncio.subprocess.PIPE)
        await proc.wait()
        os.unlink(tmp_path)
        return f"[Success] Saved {path}"
    except Exception as e: return str(e)

async def search_files_tool(pattern: str, path: str = ".") -> str:
    try:
        real_cwd = await _get_current_cwd()
        return await _exec_docker_cmd_simple(real_cwd, ["grep", "-rn", pattern, path])
    except Exception as e: return str(e)


# ==================== [æ–°å¢] ç®¡ç†å·¥å…·ï¼šè¿›ç¨‹ä¸ç½‘ç»œ ====================

async def manage_processes_tool(action: str, pid: str = None) -> str:
    """[Common] ç®¡ç†åå°è¿›ç¨‹"""
    if action == "list":
        return process_manager.list_processes()
    if action == "logs":
        if not pid: return "Error: 'pid' is required for logs."
        return process_manager.get_logs(pid)
    if action == "kill":
        if not pid: return "Error: 'pid' is required for kill."
        return await process_manager.kill_process(pid)
    return "Error: Unknown action. Use list, logs, or kill."

async def docker_manage_ports_tool(action: str, container_port: int = 8000, host_port: int = None) -> str:
    """[Docker] ç«¯å£è½¬å‘ç®¡ç†"""
    try:
        real_cwd = await _get_current_cwd()
        container_name = await get_or_create_docker_sandbox(real_cwd)
        
        if container_name not in DOCKER_PROXIES:
            DOCKER_PROXIES[container_name] = DockerPortProxy(container_name)
        proxy = DOCKER_PROXIES[container_name]
        
        if action == "list":
            return proxy.list_proxies()
        if action == "forward":
            if not host_port: host_port = container_port
            return await proxy.start_forward(host_port, container_port)
        if action == "stop":
            if not host_port: return "Error: host_port required to stop."
            return await proxy.stop_forward(host_port)
        return "Unknown action."
    except Exception as e:
        return f"[Error] Port tool failed: {str(e)}"

async def local_net_tool(action: str, port: int = None) -> str:
    """[Local] æœ¬åœ°ç½‘ç»œå·¥å…·ï¼šæ£€æŸ¥ç«¯å£å ç”¨"""
    if action == "check":
        if not port: return "Error: Port required."
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            result = s.connect_ex(('127.0.0.1', port))
            status = "OPEN/BUSY" if result == 0 else "CLOSED/FREE"
            return f"Port {port} on localhost is {status}."
    
    if action == "scan":
        # ç®€å•æ‰«æå¸¸ç”¨å¼€å‘ç«¯å£
        common_ports = [3000, 5000, 8000, 8080, 80, 443, 3306, 5432]
        results = []
        for p in common_ports:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.settimeout(0.1)
                res = s.connect_ex(('127.0.0.1', p))
                status = "BUSY" if res == 0 else "FREE"
                results.append(f"{p}: {status}")
        return "Common Ports:\n" + "\n".join(results)
        
    return "Unknown action. Use check or scan."

# ==================== æœ¬åœ°ç¯å¢ƒ (Local) å·¥å…·å®ç° ====================

def resolve_strict_path(cwd: str, sub_path: str, check_symlink: bool = True) -> Path:
    """
    ä¸¥æ ¼å·¥ä½œåŒºè·¯å¾„è§£æ
    - ç¦æ­¢ç»å¯¹è·¯å¾„
    - ç¦æ­¢ ../ éå†  
    - ç¦æ­¢é€šè¿‡ç¬¦å·é“¾æ¥æŒ‡å‘å·¥ä½œåŒºå¤–
    """
    base = Path(cwd).resolve()
    
    if not sub_path:
        return base
        
    # æ¸…ç†è¾“å…¥ï¼ˆé˜»æ­¢ç©ºå­—èŠ‚ã€æ¢è¡Œç­‰ï¼‰
    sub_path = sub_path.strip().replace('\x00', '').replace('\n', '')
    
    # æ˜¾å¼ç¦æ­¢è·¯å¾„éå†æ¨¡å¼ï¼ˆå¿«é€Ÿå¤±è´¥ï¼‰
    if '..' in sub_path.split(os.sep):
        raise PermissionError(f"Path traversal detected: {sub_path}")
    
    # ç¦æ­¢ç»å¯¹è·¯å¾„ï¼ˆWindows C:\ å’Œ Unix /ï¼‰
    if os.path.isabs(sub_path) or (len(sub_path) > 1 and sub_path[1] == ':'):
        raise PermissionError(f"Absolute paths not allowed: {sub_path}")
    
    # è§£æå®Œæ•´è·¯å¾„
    target = (base / sub_path).resolve()
    
    # å…³é”®æ£€æŸ¥ï¼šç¡®ä¿ resolve åçš„è·¯å¾„ä»åœ¨ base å†…
    try:
        target.relative_to(base)
    except ValueError:
        raise PermissionError(f"Access denied: {sub_path} resolves outside workspace")
    
    # ç¬¦å·é“¾æ¥æ£€æŸ¥ï¼ˆé˜²æ­¢ /workspace/link -> /etcï¼‰
    if check_symlink and target.exists():
        real_path = target.resolve(strict=True)
        try:
            real_path.relative_to(base)
        except ValueError:
            raise PermissionError(f"Symlink escape detected: {sub_path} -> {real_path}")
            
    return target

from typing import Tuple

def validate_bash_command(command: str, cwd: str, mode: str = "default") -> Tuple[bool, str]:
    """
    åˆ†å±‚å®‰å…¨ç­–ç•¥ï¼š
    - ç¡¬æ€§è¾¹ç•Œ (æ‰€æœ‰æ¨¡å¼): ç¦æ­¢è·¯å¾„é€ƒé€¸ï¼Œä¿æŠ¤å·¥ä½œåŒºå¤–ç³»ç»Ÿ  
    - æ¯ç­é˜²æŠ¤ (yoloä¹Ÿä¸å…è®¸): ç¦æ­¢ rm -rf /ã€æ ¼å¼åŒ–ã€dd è®¾å¤‡
    - ä¾›åº”é“¾é£é™© (ä»…ä¸¥æ ¼æ¨¡å¼): ç¦æ­¢ curl|shï¼Œyolo æ¨¡å¼è‡ªæ‹…é£é™©
    
    è¿”å›: (æ˜¯å¦å…è®¸, é”™è¯¯ä¿¡æ¯æˆ–åŸå‘½ä»¤)
    æ³¨æ„ï¼šä¸åŒ…è£…å‘½ä»¤ï¼Œå·¥ä½œç›®å½•ç”± subprocess çš„ cwd å‚æ•°æ§åˆ¶
    """
    
    # ===== ç¬¬ä¸€å±‚ï¼šç¡¬æ€§è¾¹ç•Œï¼ˆä¸å¯é€ƒé€¸ï¼‰=====
    escape_patterns = [
        (r'\.\./\.\.', "Path traversal"),                           # ../../etc
        (r'>\s*/[a-zA-Z/]+', "Write to system path"),              # > /etc/passwd  
        (r'cd\s+/[^/]', "Chdir to system root"),                   # cd /etc
        (r'~\s*/', "Home directory access"),                       # ~/.ssh
        (r'\$\{?HOME\}?', "HOME env variable"),                    # $HOME
    ]
    
    for pattern, reason in escape_patterns:
        if re.search(pattern, command, re.IGNORECASE):
            return False, f"{reason} blocked: {pattern}"
    
    # ===== ç¬¬äºŒå±‚ï¼šæ¯ç­æ€§æ“ä½œï¼ˆyolo ä¹Ÿä¸å…è®¸ï¼‰=====
    destructive_patterns = [
        (r'rm\s+-rf\s*/', "Recursive delete root"),                # rm -rf / æˆ– /xxx
        (r'mkfs\.[a-z]+', "Filesystem format"),                    # mkfs.ext4 /dev/sda
        (r'dd\s+if=.*of=/dev/[a-z]', "Direct device write"),       # dd of=/dev/sda
        (r'>?\s*/dev/(sda|hd|nvme|mmcblk)', "Block device access"), # ç›´æ¥å†™ç£ç›˜è®¾å¤‡
    ]
    
    for pattern, reason in destructive_patterns:
        if re.search(pattern, command, re.IGNORECASE):
            return False, f"Destructive operation blocked: {reason}"
    
    # ===== ç¬¬ä¸‰å±‚ï¼šä¾›åº”é“¾é£é™©ï¼ˆä»…ä¸¥æ ¼æ¨¡å¼æ‹¦æˆªï¼‰=====
    if mode != "yolo":
        supply_chain_patterns = [
            (r'curl.*\|.*sh', "Remote pipe to shell"),
            (r'wget.*\|.*sh', "Remote pipe to shell"), 
            (r'fetch.*\|.*sh', "Remote pipe to shell"),
        ]
        for pattern, reason in supply_chain_patterns:
            if re.search(pattern, command, re.I):
                return False, f"{reason} blocked in {mode} mode (use yolo to allow)"
    
    # ä¸åŒ…è£…å‘½ä»¤ï¼ç›´æ¥è¿”å›åŸå‘½ä»¤ï¼Œä¾é  subprocess çš„ cwd å‚æ•°
    return True, command


# ===== ä¿®å¤ä¹±ç ï¼šå¢åŠ  GBK è§£ç æ”¯æŒ =====
async def read_stream(stream, *, is_error: bool = False):
    """è¯»å–æµå¹¶æ·»åŠ é”™è¯¯å‰ç¼€ï¼Œæ”¯æŒ Windows ä¸­æ–‡ç¼–ç """
    if stream is None:
        return
    async for line in stream:
        prefix = "[ERROR] " if is_error else ""
        
        # Windows ä¸­æ–‡ç³»ç»Ÿé€šå¸¸ç”¨ GBKï¼Œå…ˆå°è¯• UTF-8ï¼Œå¤±è´¥åˆ™å°è¯• GBK
        try:
            decoded = line.decode('utf-8').rstrip()
        except UnicodeDecodeError:
            try:
                decoded = line.decode('gbk').rstrip()
            except:
                decoded = line.decode('utf-8', errors='replace').rstrip()
                
        yield f"{prefix}{decoded}"


async def bash_tool_local(command: str, background: bool = False) -> str | AsyncIterator[str]:
    """[Local] æ‰§è¡Œå‘½ä»¤ï¼Œæ”¯æŒåå°"""
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    perm = settings.get("localEnvSettings", {}).get("permissionMode", "default")
    
    if not cwd: 
        return "Error: No workspace."
    
    # å®‰å…¨æ£€æŸ¥ï¼ˆä¸å†åŒ…è£… cd å‘½ä»¤ï¼‰
    allowed, result = validate_bash_command(command, cwd, mode=perm)
    if not allowed:
        return f"[Security] Command blocked: {result}"
    
    # ä¿æŒå’ŒåŸç‰ˆå®Œå…¨ä¸€è‡´ï¼šä¸ä¿®æ”¹ commandï¼Œåªæ£€æŸ¥

    system = platform.system()
    if system == "Windows":
        is_ps = any(x in command.lower() for x in ['|', 'get-', 'echo'])
        exe = "powershell.exe" if is_ps else "cmd.exe"
        args = ["-Command", command] if is_ps else ["/c", command]
    else:
        exe = os.environ.get('SHELL', '/bin/bash')
        args = ["-c", command]

    try:
        proc = await asyncio.create_subprocess_exec(
            exe, *args,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE,
            cwd=cwd,  # â† åŸç‰ˆé€»è¾‘ï¼šé è¿™ä¸ªè®¾ç½®ç›®å½•ï¼Œä¸åœ¨å‘½ä»¤é‡Œ cd
            env=os.environ.copy()
        )

        if background:
            pid = await process_manager.register_process(proc, command, "local")
            return f"[SUCCESS] Background process started.\nPID: {pid}\nUse 'manage_processes_local' to check."

        async def _stream():
            yielded = False
            async for line in _merge_streams(read_stream(proc.stdout), read_stream(proc.stderr, is_error=True)):
                yield line
                yielded = True
            await proc.wait()
            if proc.returncode != 0: 
                yield f"[EXIT] {proc.returncode}"
            elif not yielded: 
                yield "[SUCCESS] No output."
        return _stream()
    except Exception as e: 
        return str(e)

# æ¢å¤åŸæœ‰çš„ Local æ–‡ä»¶å·¥å…·
async def list_files_tool_local(path: str = ".", show_all: bool = False) -> str:
    """[Local] åˆ—å‡ºæ–‡ä»¶ï¼šä¼˜å…ˆæ˜¾ç¤ºç›®å½•ï¼Œæ”¯æŒæ•°é‡æˆªæ–­ï¼Œè¿‡æ»¤éšè—æ–‡ä»¶"""
    try:
        cwd = await _get_current_cwd()
        target = resolve_strict_path(cwd, path, check_symlink=True)
        
        if not target.is_dir():
            return f"[Error] Not a directory: {path}"

        # ä½¿ç”¨ scandir è·å–æ›´è¯¦ç»†çš„ä¿¡æ¯ä¸”é€Ÿåº¦æ›´å¿«
        entries = []
        try:
            with os.scandir(target) as it:
                for entry in it:
                    if not show_all and entry.name.startswith('.'):
                        continue
                    
                    is_dir = entry.is_dir()
                    # æ ¼å¼ï¼š(æ˜¯å¦ç›®å½•, æ’åºå, æ˜¾ç¤ºå­—ç¬¦ä¸²)
                    # ç›®å½•æ’åœ¨å‰é¢ (0)ï¼Œæ–‡ä»¶æ’åœ¨åé¢ (1)
                    display_name = f"{entry.name}/" if is_dir else entry.name
                    entries.append((0 if is_dir else 1, entry.name.lower(), display_name))
        except PermissionError:
            return f"[Error] Permission denied accessing: {path}"

        # æ’åºï¼šå…ˆæŒ‰ç›®å½•/æ–‡ä»¶åˆ†ï¼Œå†æŒ‰åç§°å­—æ¯åº
        entries.sort()

        # æ•°é‡æˆªæ–­é˜²æ­¢ Token çˆ†ç‚¸
        MAX_ITEMS = 200
        result_lines = [e[2] for e in entries[:MAX_ITEMS]]
        
        summary = f"Total: {len(entries)} items"
        if len(entries) > MAX_ITEMS:
            summary += f" (Showing first {MAX_ITEMS})"
            result_lines.append(f"... {len(entries) - MAX_ITEMS} more items")
        
        return f"{summary} in {path}:\n" + "\n".join(result_lines) if result_lines else "Empty directory."

    except Exception as e:
        return f"[Error] List failed: {str(e)}"

async def read_file_tool_local(path: str) -> str:
    """[Local] è¯»å–æ–‡ä»¶ï¼šæ”¯æŒå¤§æ–‡ä»¶æˆªæ–­è¯»å– (Max 2000è¡Œ)ï¼Œè‡ªåŠ¨æ£€æµ‹äºŒè¿›åˆ¶æ–‡ä»¶"""
    try:
        cwd = await _get_current_cwd()
        target = resolve_strict_path(cwd, path, check_symlink=True)

        if not target.exists():
            return f"[Error] File not found: {path}"
        
        if not target.is_file():
            return f"[Error] Not a file: {path}"

        # 1. äºŒè¿›åˆ¶æ–‡ä»¶å¿«é€Ÿæ£€æµ‹ (è¯»å–å‰1KBæ£€æŸ¥ç©ºå­—èŠ‚)
        try:
            with open(target, 'rb') as f_bin:
                chunk = f_bin.read(1024)
                if b'\0' in chunk:
                    return f"[Error] Cannot read binary file: {path}"
        except Exception as e:
            return f"[Error] Failed to check file type: {str(e)}"

        # 2. é™åˆ¶è¯»å–å¤§å°ï¼Œé˜²æ­¢å†…å­˜çˆ†ç‚¸
        MAX_LINES = 2000
        MAX_BYTES = 500 * 1024  # 500KB Limit
        
        file_size = target.stat().st_size
        truncated = False
        
        async with aiofiles.open(target, 'r', encoding='utf-8', errors='replace') as f:
            # å¦‚æœæ–‡ä»¶è¿‡å¤§ï¼Œåªè¯»å–éƒ¨åˆ†å­—ç¬¦
            if file_size > MAX_BYTES:
                content = await f.read(MAX_BYTES)
                truncated = True
                lines = content.splitlines()
                # ä¸¢å¼ƒæœ€åä¸€è¡Œï¼Œå› ä¸ºå¯èƒ½è¢«å­—èŠ‚é™åˆ¶æˆªæ–­äº†ä¸€åŠ
                if lines: lines.pop()
            else:
                lines = await f.readlines()
                # å»é™¤æœ«å°¾æ¢è¡Œç¬¦
                lines = [l.rstrip('\n') for l in lines]

        # è¡Œæ•°æˆªæ–­
        if len(lines) > MAX_LINES:
            lines = lines[:MAX_LINES]
            truncated = True

        # æ ¼å¼åŒ–è¾“å‡ºï¼šè¡Œå· + å†…å®¹
        output = [f"{i+1:4} | {line}" for i, line in enumerate(lines)]
        
        if truncated:
            output.append(f"\n... [Warning] File content truncated (Too large). Showing first {len(lines)} lines.")
            
        return "\n".join(output)

    except Exception as e:
        return f"[Error] Read failed: {str(e)}"

async def edit_file_tool_local(path: str, content: str) -> str:
    """[Local] å†™å…¥æ–‡ä»¶ï¼šè‡ªåŠ¨åˆ›å»º .bak å¤‡ä»½ï¼ŒåŸå­å†™å…¥é˜²æŸå"""
    try:
        cwd = await _get_current_cwd()
        target = resolve_strict_path(cwd, path, check_symlink=True)
        
        # 1. ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
        parent_dir = target.parent
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿çˆ¶ç›®å½•ä¹Ÿåœ¨å·¥ä½œåŒºå†…
        resolve_strict_path(cwd, str(parent_dir), check_symlink=True)
        await aiofiles.os.makedirs(parent_dir, exist_ok=True)

        # 2. åˆ›å»ºå¤‡ä»½ (å¦‚æœæ–‡ä»¶å­˜åœ¨)
        backup_msg = ""
        if target.exists():
            try:
                # ç®€å•çš„å¤‡ä»½ç­–ç•¥ï¼šfilename.bak
                # å¦‚æœæ˜¯è¦†ç›–å†™ï¼Œä¿ç•™ä¸€ä¸ªåæ‚”è¯éå¸¸é‡è¦
                backup_path = target.with_suffix(target.suffix + ".bak")
                # ä½¿ç”¨ shutil è¿›è¡ŒåŒæ­¥å¤åˆ¶ (æ–‡ä»¶æ“ä½œé€šå¸¸å¾ˆå¿«ï¼Œä¸ä¼šé˜»å¡å¤ªä¹…)
                shutil.copy2(target, backup_path)
                backup_msg = f" (Backup created: {backup_path.name})"
            except Exception as e:
                print(f"[Warn] Backup failed: {e}")

        # 3. åŸå­å†™å…¥ (Atomic Write)
        # å…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½åã€‚é˜²æ­¢å†™å…¥ä¸€åŠæ—¶è„šæœ¬å´©æºƒå¯¼è‡´æ–‡ä»¶å†…å®¹ä¸¢å¤±
        temp_path = target.with_suffix(target.suffix + f".tmp.{uuid.uuid4().hex[:6]}")
        
        try:
            async with aiofiles.open(temp_path, 'w', encoding='utf-8') as f:
                await f.write(content)
            
            # åŸå­æ›¿æ¢ (POSIX ç³»ç»Ÿä¸Šæ˜¯åŸå­çš„ï¼ŒWindows ä¸Šæœ€è¿‘çš„ç‰ˆæœ¬ä¹Ÿæ˜¯)
            if os.path.exists(target):
                os.replace(temp_path, target)
            else:
                os.rename(temp_path, target)
                
        except Exception as e:
            if os.path.exists(temp_path):
                os.remove(temp_path)
            raise e

        return f"Saved successfully{backup_msg}."

    except Exception as e:
        return f"[Error] Edit failed: {str(e)}"

async def search_files_tool_local(pattern: str, path: str = ".") -> str:
    """[Local] æ™ºèƒ½æœç´¢ï¼šä¼˜å…ˆå°è¯• git grep/grepï¼Œå›é€€åˆ°ä¼˜åŒ–çš„ Python å®ç°"""
    try:
        cwd = await _get_current_cwd()
        target_dir = resolve_strict_path(cwd, path, check_symlink=True)
        target_str = str(target_dir)
        
        # 1. å°è¯•ä½¿ç”¨ git grep (é€Ÿåº¦æœ€å¿«ï¼Œä¸”è‡ªåŠ¨å°Šé‡ .gitignore)
        # åªæœ‰å½“åœ¨ git ä»“åº“å†…ä¸”å®‰è£…äº† git æ—¶æœ‰æ•ˆ
        if os.path.isdir(os.path.join(cwd, ".git")) and shutil.which("git"):
            try:
                # -I: ä¸æœç´¢äºŒè¿›åˆ¶, -n: è¡Œå·, --full-name: ç›¸å¯¹è·¯å¾„
                cmd = ["git", "grep", "-I", "-n", "--full-name", pattern]
                # å¦‚æœæŒ‡å®šäº†å­ç›®å½•ï¼Œé™åˆ¶æœç´¢èŒƒå›´
                rel_path = os.path.relpath(target_str, cwd)
                if rel_path != ".":
                    cmd.append(rel_path)
                
                proc = await asyncio.create_subprocess_exec(
                    *cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE, cwd=cwd
                )
                stdout, _ = await proc.communicate()
                if proc.returncode == 0 and stdout:
                    return stdout.decode('utf-8', errors='replace').strip()
            except Exception:
                pass # git grep å¤±è´¥åˆ™å›é€€

        # 2. ä¼˜åŒ–çš„ Python å®ç° (Ripgrep-lite)
        matches = []
        regex = re.compile(pattern)
        MAX_RESULTS = 1000  # é˜²æ­¢ç»“æœçˆ†ç‚¸
        
        # å®šä¹‰éœ€è¦è·³è¿‡çš„ç›®å½•å’Œæ‰©å±•å
        SKIP_DIRS = {'.git', 'node_modules', '__pycache__', 'venv', '.env', 'dist', 'build', 'coverage'}
        SKIP_EXTS = {'.pyc', '.pyo', '.so', '.dll', '.exe', '.bin', '.png', '.jpg', '.jpeg', '.gif', '.zip', '.tar', '.gz'}

        # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºäºŒè¿›åˆ¶ (è¯»å–å‰ 1024 å­—èŠ‚æ£€æŸ¥ NULL)
        def is_binary(file_path):
            try:
                with open(file_path, 'rb') as f:
                    chunk = f.read(1024)
                    return b'\0' in chunk
            except:
                return True

        for root, dirs, files in os.walk(target_str, topdown=True):
            # å‰ªæï¼šç›´æ¥ä¿®æ”¹ dirs åˆ—è¡¨ï¼Œé˜»æ­¢ os.walk è¿›å…¥è¿™äº›ç›®å½•
            dirs[:] = [d for d in dirs if d not in SKIP_DIRS and not d.startswith('.')]
            
            for file in files:
                if any(file.endswith(ext) for ext in SKIP_EXTS): continue
                
                full_path = os.path.join(root, file)
                # ç›¸å¯¹è·¯å¾„ç”¨äºæ˜¾ç¤º
                display_path = os.path.relpath(full_path, cwd)
                
                if is_binary(full_path): continue

                try:
                    # ä½¿ç”¨ aiofiles å¼‚æ­¥è¯»å–æ–‡æœ¬
                    async with aiofiles.open(full_path, 'r', encoding='utf-8', errors='replace') as f:
                        content = await f.read()
                        lines = content.splitlines()
                        for i, line in enumerate(lines, 1):
                            if regex.search(line):
                                # æˆªæ–­è¿‡é•¿çš„è¡Œ
                                clean_line = line.strip()[:200]
                                matches.append(f"{display_path}:{i}:{clean_line}")
                                if len(matches) >= MAX_RESULTS:
                                    return "\n".join(matches) + f"\n... (Truncated at {MAX_RESULTS} matches)"
                except Exception:
                    continue

        return "\n".join(matches) if matches else "No matches found."
    except Exception as e:
        return f"[Error] Search failed: {str(e)}"
    
async def glob_files_tool_local(pattern: str, exclude: str = "") -> str:
    """[Local] æ™ºèƒ½æŸ¥æ‰¾ï¼šä¼˜å…ˆ git ls-filesï¼Œæ”¯æŒé«˜æ•ˆå‰ªæéå†"""
    try:
        cwd = await _get_current_cwd()
        base = Path(cwd).resolve()
        
        # å®‰å…¨æ£€æŸ¥
        if '..' in pattern: return "[Security] Glob pattern cannot contain '..'"

        excludes = [e.strip() for e in exclude.split(",") if e.strip()]
        # é»˜è®¤æ’é™¤å¸¸è§åƒåœ¾ç›®å½•
        DEFAULT_EXCLUDES = {'.git', 'node_modules', '__pycache__', 'venv', 'dist', 'build', '.idea', '.vscode'}
        
        results = []

        # 1. å°è¯•ä½¿ç”¨ git ls-files (æœ€å‡†ç¡®ï¼Œéµå¾ª .gitignore)
        # åªæœ‰å½“åœ¨ git ä»“åº“ä¸”æ²¡æœ‰å¤æ‚çš„ pattern é€šé…ç¬¦æ—¶ä½¿ç”¨
        use_git = False
        if os.path.isdir(os.path.join(cwd, ".git")) and shutil.which("git"):
             # git ls-files æ”¯æŒç®€å•çš„ globï¼Œä½†å¤æ‚çš„å¯èƒ½ä¸æ”¯æŒï¼Œè¿™é‡Œä¸»è¦ç”¨äºå…¨é‡åˆ—å‡º
            if pattern == "**/*" or pattern == ".":
                try:
                    proc = await asyncio.create_subprocess_exec(
                        "git", "ls-files", "--cached", "--others", "--exclude-standard",
                        stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE, cwd=cwd
                    )
                    stdout, _ = await proc.communicate()
                    if proc.returncode == 0 and stdout:
                        files = stdout.decode().splitlines()
                        # åº”ç”¨é¢å¤–çš„ fnmatch è¿‡æ»¤
                        for f in files:
                            if not any(fnmatch.fnmatch(f, ex) for ex in excludes):
                                results.append(f)
                        use_git = True
                except:
                    pass

        # 2. å¦‚æœ git å¤±è´¥æˆ–ä¸é€‚ç”¨ï¼Œä½¿ç”¨ä¼˜åŒ–çš„ os.walk (å¸¦å‰ªæ)
        if not use_git:
            # å°†æ¨¡å¼æ‹†åˆ†ä¸ºç›®å½•éƒ¨åˆ†å’Œæ–‡ä»¶éƒ¨åˆ†ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            # å¦‚æœ pattern æ˜¯ç®€å•çš„ "**/*" æˆ– "*.py"ï¼Œæˆ‘ä»¬éå†æ•´ä¸ªæ ‘
            is_recursive = "**" in pattern
            search_ext = pattern.split("*")[-1] if pattern.startswith("*") else None
            
            for root, dirs, files in os.walk(str(base), topdown=True):
                # å…³é”®ä¼˜åŒ–ï¼šåŸåœ°ä¿®æ”¹ dirs ä»¥å‰ªæ
                dirs[:] = [d for d in dirs if d not in DEFAULT_EXCLUDES and not d.startswith('.')]
                
                rel_root = Path(root).relative_to(base)
                
                for name in files:
                    file_rel_path = str(rel_root / name)
                    if file_rel_path.startswith("./"): file_rel_path = file_rel_path[2:]

                    # æ£€æŸ¥æ’é™¤é¡¹
                    if any(fnmatch.fnmatch(file_rel_path, ex) for ex in excludes):
                        continue
                    
                    # æ£€æŸ¥åŒ¹é…é¡¹
                    if fnmatch.fnmatch(file_rel_path, pattern) or (search_ext and name.endswith(search_ext)):
                        results.append(file_rel_path)

        # é™åˆ¶è¿”å›æ•°é‡
        limit = 200
        output = sorted(results)
        if len(output) > limit:
            return "\n".join(output[:limit]) + f"\n... ({len(output)-limit} more files)"
        return "\n".join(output) if output else "No files matched."
        
    except Exception as e:
        return f"[Error] {str(e)}"
    
async def edit_file_patch_tool_local(path: str, old_string: str, new_string: str) -> str:
    """[Local] ç²¾ç¡®æ›¿æ¢ï¼šè‡ªåŠ¨å¤„ç†æ¢è¡Œç¬¦å·®å¼‚ (CRLF/LF) ä¸ç©ºç™½å­—ç¬¦å®¹é”™"""
    try:
        cwd = await _get_current_cwd()
        target = resolve_strict_path(cwd, path, check_symlink=True)
        
        if not target.exists():
            return f"[Error] File not found: {path}"

        # è¯»å–æ–‡ä»¶å†…å®¹
        async with aiofiles.open(target, 'r', encoding='utf-8') as f:
            content = await f.read()

        # --- ç­–ç•¥ 1: ç›´æ¥æ›¿æ¢ (æœ€å¿«) ---
        if old_string in content:
            new_content = content.replace(old_string, new_string, 1)
            async with aiofiles.open(target, 'w', encoding='utf-8') as f:
                await f.write(new_content)
            return "Patched successfully (Exact match)."

        # --- ç­–ç•¥ 2: å½’ä¸€åŒ–æ¢è¡Œç¬¦åæ›¿æ¢ (å¤„ç† Windows/Linux å·®å¼‚) ---
        # å°†æ‰€æœ‰ \r\n è½¬æ¢ä¸º \n è¿›è¡Œæ¯”å¯¹
        content_normalized = content.replace('\r\n', '\n')
        old_normalized = old_string.replace('\r\n', '\n')
        new_normalized = new_string.replace('\r\n', '\n')

        if old_normalized in content_normalized:
            # è¿™é‡Œçš„éš¾ç‚¹æ˜¯ï¼šå¦‚æœæˆ‘ä»¬åœ¨ normalized ç‰ˆæœ¬ä¸­æ›¿æ¢äº†ï¼Œ
            # æˆ‘ä»¬éœ€è¦æŠŠå†™å›çš„å†…å®¹æœ€å¥½ä¿æŒåŸæ–‡ä»¶çš„æ¢è¡Œç¬¦é£æ ¼ã€‚
            # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç»Ÿä¸€å†™å› normalized çš„å†…å®¹ (Python write é€šå¸¸ä¼šè‡ªåŠ¨å¤„ç† OS æ¢è¡Œ)
            new_content_normalized = content_normalized.replace(old_normalized, new_normalized, 1)
            async with aiofiles.open(target, 'w', encoding='utf-8') as f:
                await f.write(new_content_normalized)
            return "Patched successfully (Normalized line endings match)."

        # --- ç­–ç•¥ 3: å®¹é”™åŒ¹é… (å¿½ç•¥è¡Œå°¾ç©ºæ ¼) ---
        # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•é€è¡Œå¯¹æ¯”ï¼Œå¿½ç•¥ strip() åçš„å·®å¼‚
        lines = content.splitlines()
        old_lines = old_string.splitlines()
        
        if not old_lines: return "[Error] old_string is empty."

        # ç®€å•çš„æ»‘åŠ¨çª—å£åŒ¹é…
        match_index = -1
        for i in range(len(lines) - len(old_lines) + 1):
            match = True
            for j in range(len(old_lines)):
                if lines[i+j].strip() != old_lines[j].strip():
                    match = False
                    break
            if match:
                match_index = i
                break
        
        if match_index != -1:
            # æ‰¾åˆ°äº†é€»è¾‘ä¸ŠåŒ¹é…çš„å—ï¼Œè¿›è¡Œæ›¿æ¢
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ new_string (ä¿æŒ AI ç”Ÿæˆçš„æ ¼å¼)
            # ä½†æˆ‘ä»¬éœ€è¦å°å¿ƒç¼©è¿›ã€‚è¿™é‡Œå‡è®¾ AI æä¾›äº†æ­£ç¡®çš„ new_string ç¼©è¿›ã€‚
            pre_content = "\n".join(lines[:match_index])
            post_content = "\n".join(lines[match_index + len(old_lines):])
            
            # æ‹¼æ¥æ—¶è¦æ³¨æ„åŸæ–‡ä»¶çš„æ¢è¡Œç¬¦ï¼Œè¿™é‡Œç®€åŒ–ä¸º \n
            final_content = (pre_content + "\n" + new_string + "\n" + post_content).strip()
            
            async with aiofiles.open(target, 'w', encoding='utf-8') as f:
                await f.write(final_content)
            return "Patched successfully (Fuzzy match: ignored whitespace/indentation differences)."

        # --- å¤±è´¥ï¼šæä¾›è¯¦ç»†è¯Šæ–­ä¿¡æ¯ ---
        # å¸®åŠ© AI æ‰¾åˆ°å®ƒå¯èƒ½æƒ³æ”¹çš„åœ°æ–¹
        first_line = old_lines[0].strip()[:50]
        candidates = []
        for i, line in enumerate(lines):
            if first_line in line.strip():
                candidates.append(f"Line {i+1}: {line.strip()[:80]}")
        
        error_msg = f"[Error] old_string not found in '{path}'.\n"
        error_msg += "Check line endings or indentation.\n"
        if candidates:
            error_msg += "Did you mean one of these locations?\n" + "\n".join(candidates[:3])
            
        return error_msg

    except Exception as e:
        return f"[Error] Patch failed: {str(e)}"

async def todo_write_tool_local(action: str, id: str = None, content: str = None, priority: str = "medium", status: str = None) -> str:
    """æœ¬åœ°ç¯å¢ƒä»»åŠ¡ç®¡ç†"""
    try:
        # 1. è·å–å½“å‰å·¥ä½œç›®å½•å¹¶ç¡®ä¿ .party æ–‡ä»¶å¤¹å­˜åœ¨
        cwd = await _get_current_cwd()
        party_dir = Path(cwd) / ".party"
        if not party_dir.exists():
            await aiofiles.os.makedirs(party_dir, exist_ok=True)
        
        todo_file = party_dir / "ai_todos.json"
        
        # 2. è¯»å–ç°æœ‰æ•°æ®
        todos = []
        if todo_file.exists():
            try:
                async with aiofiles.open(todo_file, 'r', encoding='utf-8') as f:
                    file_content = await f.read()
                    if file_content.strip():
                        todos = json.loads(file_content)
            except (json.JSONDecodeError, Exception) as e:
                print(f"è¯»å– Todo æ–‡ä»¶å¤±è´¥ï¼Œå°†åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨: {e}")
                todos = []
            
        msg = ""

        # 3. æ‰§è¡Œé€»è¾‘æ“ä½œ
        if action == "create":
            if not content: 
                return "[Error] Content required for creation."
            new_todo = {
                "id": id or str(uuid.uuid4())[:8],
                "content": content,
                "priority": priority,
                "status": "pending",
                "created_at": datetime.now().isoformat()
            }
            todos.append(new_todo)
            msg = f"[Success] Created local todo: {new_todo['id']}"
            
        elif action == "list":
            if not todos: 
                return "No todos found in this project."
            lines = ["ğŸ“‹ **Project Todos (Local)**:"]
            # æ’åºï¼šæœªå®Œæˆçš„åœ¨å‰ï¼Œå·²å®Œæˆçš„åœ¨å
            sorted_todos = sorted(todos, key=lambda x: x.get('status') == 'done')
            for t in sorted_todos:
                status_icon = "âœ…" if t.get('status') == 'done' else "â³"
                priority_map = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
                p_icon = priority_map.get(t.get('priority', 'medium'), "âšª")
                lines.append(f"{status_icon} {p_icon} [{t['id']}] {t['content'][:50]}")
            return "\n".join(lines)

        elif action in ["update", "toggle", "delete"]:
            if not id: 
                return "[Error] ID required for update/toggle/delete."
            
            target = next((t for t in todos if t['id'] == id), None)
            if not target: 
                return f"[Error] ID {id} not found."
            
            if action == "delete":
                todos.remove(target)
                msg = f"[Success] Deleted local todo: {id}"

            elif action == "toggle":
                # åˆ‡æ¢é€»è¾‘
                if target.get('status') != 'done':
                    target['status'] = 'done'
                    target['completed_at'] = datetime.now().isoformat() # è®°å½•å®Œæˆæ—¶é—´
                else:
                    target['status'] = 'pending'
                    target['completed_at'] = None # é‡ç½®å®Œæˆæ—¶é—´
                msg = f"[Success] Toggled local todo {id} to {target['status']}"

            elif action == "update":
                if content: target['content'] = content
                if priority: target['priority'] = priority
                
                # å¤„ç†çŠ¶æ€æ›´æ–°å’Œå®Œæˆæ—¶é—´
                if status:
                    # å¦‚æœçŠ¶æ€ä»é done å˜ä¸º done
                    if status == "done" and target.get('status') != "done":
                        target['completed_at'] = datetime.now().isoformat()
                    # å¦‚æœçŠ¶æ€ä» done å˜ä¸ºé done
                    elif status != "done" and target.get('status') == "done":
                        target['completed_at'] = None
                    
                    target['status'] = status
                
                target['updated_at'] = datetime.now().isoformat()
                msg = f"[Success] Updated local todo: {id}"
        else:
            return f"[Error] Unknown action: {action}"

        # 4. å¼‚æ­¥å†™å›æœ¬åœ°æ–‡ä»¶
        async with aiofiles.open(todo_file, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(todos, indent=2, ensure_ascii=False))
            
        return msg

    except Exception as e:
        return f"[Error] Local Todo operation failed: {str(e)}"
# ==================== Claude & Qwen Agents (æ¢å¤) ====================

cli_info = "è¿™æ˜¯ä¸€ä¸ªäº¤äº’å¼å‘½ä»¤è¡Œå·¥å…·..."

async def claude_code_async(prompt) -> str | AsyncIterator[str]:
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    ccSettings = settings.get("ccSettings", {})
    if not cwd: return "No working directory."
    
    extra_config = {}
    if ccSettings.get("enabled"):
        extra_config = {
            "ANTHROPIC_BASE_URL": ccSettings.get("base_url"),
            "ANTHROPIC_API_KEY": ccSettings.get("api_key"),
            "ANTHROPIC_MODEL": ccSettings.get("model"),
        }
        extra_config = {k: str(v) if v else "" for k, v in extra_config.items()}

    async def _stream():
        options = ClaudeAgentOptions(
            cwd=cwd,
            continue_conversation=True,
            permission_mode=ccSettings.get("permissionMode", "default"),
            env={**os.environ, **extra_config}
        )
        async for message in query(prompt=prompt, options=options):
            if isinstance(message, AssistantMessage):
                for block in message.content:
                    if isinstance(block, TextBlock): yield block.text
    return _stream()

async def qwen_code_async(prompt: str) -> str | AsyncIterator[str]:
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    qcSettings = settings.get("qcSettings", {})
    if not cwd: return "No working directory."

    extra_config = {}
    if qcSettings.get("enabled"):
        extra_config = {
            "OPENAI_BASE_URL": str(qcSettings.get("base_url") or ""),
            "OPENAI_API_KEY": str(qcSettings.get("api_key") or ""),
            "OPENAI_MODEL": str(qcSettings.get("model") or ""),
        }
    executable = shutil.which("qwen") or "qwen"

    async def _stream():
        try:
            process = await asyncio.create_subprocess_exec(
                executable, "-p", prompt, "--approval-mode", qcSettings.get("permissionMode", "default"),
                stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE,
                cwd=cwd, env={**os.environ, **extra_config}
            )
            async for out in _merge_streams(read_stream(process.stdout), read_stream(process.stderr, is_error=True)):
                yield out
            await process.wait()
        except Exception as e: yield str(e)
    return _stream()

# ==================== å·¥å…·æ³¨å†Œè¡¨ (å®Œæ•´) ====================

TOOLS_REGISTRY = {
    # --- åªè¯» ---
    "list_files": {
        "type": "function", "function": {
            "name": "list_files_tool", "description": "List files in docker workspace.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "show_all": {"type": "boolean"}}}
        }
    },
    "read_file": {
        "type": "function", "function": {
            "name": "read_file_tool", "description": "Read file content.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"]}
        }
    },
    "search_files": {
        "type": "function", "function": {
            "name": "search_files_tool", "description": "Grep search.",
            "parameters": {"type": "object", "properties": {"pattern": {"type": "string"}, "path": {"type": "string"}}, "required": ["pattern"]}
        }
    },
    "glob_files": {
        "type": "function", "function": {
            "name": "glob_files_tool", "description": "Recursive glob.",
            "parameters": {"type": "object", "properties": {"pattern": {"type": "string"}, "exclude": {"type": "string"}}, "required": ["pattern"]}
        }
    },
    # --- ç¼–è¾‘ ---
    "edit_file": {
        "type": "function", "function": {
            "name": "edit_file_tool", "description": "Overwrite file.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "content": {"type": "string"}}, "required": ["path", "content"]}
        }
    },
    "edit_file_patch": {
        "type": "function", "function": {
            "name": "edit_file_patch_tool", "description": "Precise replacement.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "old_string": {"type": "string"}, "new_string": {"type": "string"}}, "required": ["path", "old_string"]}
        }
    },
    # --- ä»»åŠ¡ ---
    "todo_write": {
        "type": "function", "function": {
            "name": "todo_write_tool", "description": "Manage tasks.",
            "parameters": {"type": "object", "properties": {"action": {"type": "string", "enum": ["create","list","update","delete","toggle"]}, "content": {"type": "string"}, "id": {"type": "string"}}, "required": ["action"]}
        }
    },
    # --- åŸºç¡€è®¾æ–½ (æ ¸å¿ƒæ›´æ–°) ---
    "bash": {
        "type": "function", "function": {
            "name": "docker_sandbox_async", "description": "Run bash in Docker.",
            "parameters": {
                "type": "object", "properties": {
                    "command": {"type": "string"}, 
                    "background": {"type": "boolean", "description": "Run non-blocking (server/watcher). Returns PID."}
                }, "required": ["command"]
            }
        }
    },
    "manage_processes": {
        "type": "function", "function": {
            "name": "manage_processes_tool", "description": "Check logs or kill background processes (Docker & Local).",
            "parameters": {
                "type": "object", "properties": {
                    "action": {"type": "string", "enum": ["list", "logs", "kill"]},
                    "pid": {"type": "string"}
                }, "required": ["action"]
            }
        }
    },
    "manage_ports": {
        "type": "function", "function": {
            "name": "docker_manage_ports_tool", "description": "Forward Docker ports to localhost.",
            "parameters": {
                "type": "object", "properties": {
                    "action": {"type": "string", "enum": ["forward", "stop", "list"]},
                    "container_port": {"type": "integer"},
                    "host_port": {"type": "integer"}
                }, "required": ["action"]
            }
        }
    }
}

LOCAL_TOOLS_REGISTRY = {
    # --- åªè¯» ---
    "list_files_local": {
        "type": "function", "function": {
            "name": "list_files_tool_local", "description": "List local files.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}}}
        }
    },
    "read_file_local": {
        "type": "function", "function": {
            "name": "read_file_tool_local", "description": "Read local file.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}}, "required": ["path"]}
        }
    },
    "search_files_local": {
         "type": "function", "function": {
            "name": "search_files_tool_local", "description": "Search local files.",
            "parameters": {"type": "object", "properties": {"pattern": {"type": "string"}}, "required": ["pattern"]}
        }
    },
    "glob_files_local": {
         "type": "function", "function": {
            "name": "glob_files_tool_local", "description": "Glob local files.",
            "parameters": {"type": "object", "properties": {"pattern": {"type": "string"}}, "required": ["pattern"]}
        }
    },
    # --- ç¼–è¾‘ ---
    "edit_file_local": {
        "type": "function", "function": {
            "name": "edit_file_tool_local", "description": "Write local file.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "content": {"type": "string"}}, "required": ["path"]}
        }
    },
    "edit_file_patch_local": {
        "type": "function", "function": {
            "name": "edit_file_patch_tool_local", "description": "Patch local file.",
            "parameters": {"type": "object", "properties": {"path": {"type": "string"}, "old_string": {"type": "string"}, "new_string": {"type": "string"}}, "required": ["path", "old_string"]}
        }
    },
    "todo_write_local": {
        "type": "function", "function": {
            "name": "todo_write_tool_local", "description": "Manage local tasks.",
            "parameters": {"type": "object", "properties": {"action": {"type": "string", "enum": ["create","list","update","delete","toggle"]}, "content": {"type": "string"}, "id": {"type": "string"}}, "required": ["action"]}
        }
    },
    # --- åŸºç¡€è®¾æ–½ (æ ¸å¿ƒæ›´æ–°) ---
    "bash_local": {
        "type": "function", "function": {
            "name": "bash_tool_local", "description": "Run local command.",
            "parameters": {
                "type": "object", "properties": {
                    "command": {"type": "string"},
                    "background": {"type": "boolean", "description": "Run in background."}
                }, "required": ["command"]
            }
        }
    },
    "manage_processes_local": {
        "type": "function", "function": {
            "name": "manage_processes_tool", "description": "Manage local background processes.",
            "parameters": {
                "type": "object", "properties": {
                    "action": {"type": "string", "enum": ["list", "logs", "kill"]},
                    "pid": {"type": "string"}
                }, "required": ["action"]
            }
        }
    },
    "local_net_tool": {
        "type": "function", "function": {
            "name": "local_net_tool", "description": "Check local ports.",
            "parameters": {
                "type": "object", "properties": {
                    "action": {"type": "string", "enum": ["check", "scan"]},
                    "port": {"type": "integer"}
                }, "required": ["action"]
            }
        }
    }
}

# ä»£ç†å·¥å…·å®šä¹‰ (ç”¨äºå…¶ä»–Agent)
claude_code_tool = {
    "type": "function",
    "function": {
        "name": "claude_code_async",
        "description": f"Interact with Claude Code Agent. {cli_info}",
        "parameters": {"type": "object", "properties": {"prompt": {"type": "string"}}, "required": ["prompt"]}
    }
}
qwen_code_tool = {
    "type": "function",
    "function": {
        "name": "qwen_code_async",
        "description": f"Interact with Qwen Code Agent. {cli_info}",
        "parameters": {"type": "object", "properties": {"prompt": {"type": "string"}}, "required": ["prompt"]}
    }
}

def get_tools_for_mode(mode: str) -> list:
    """è·å– Docker ç¯å¢ƒå·¥å…·é›†"""
    # åŸºç¡€åªè¯»
    read = [TOOLS_REGISTRY["list_files"], TOOLS_REGISTRY["read_file"], TOOLS_REGISTRY["search_files"], TOOLS_REGISTRY["glob_files"]]
    # ç¼–è¾‘
    edit = [TOOLS_REGISTRY["edit_file"], TOOLS_REGISTRY["edit_file_patch"], TOOLS_REGISTRY["todo_write"]]
    # åŸºç¡€è®¾æ–½ (æ‰§è¡Œ/è¿›ç¨‹/ç«¯å£)
    infra = [TOOLS_REGISTRY["bash"], TOOLS_REGISTRY["manage_processes"], TOOLS_REGISTRY["manage_ports"]]
    
    if mode == "default": return read
    if mode == "auto-approve": return read + edit + [TOOLS_REGISTRY["manage_processes"]]
    if mode == "yolo": return read + edit + infra
    return read

def get_local_tools_for_mode(mode: str) -> list:
    """è·å– Local ç¯å¢ƒå·¥å…·é›†"""
    read = [
        LOCAL_TOOLS_REGISTRY["list_files_local"], LOCAL_TOOLS_REGISTRY["read_file_local"], 
        LOCAL_TOOLS_REGISTRY["search_files_local"], LOCAL_TOOLS_REGISTRY["glob_files_local"]
    ]
    edit = [LOCAL_TOOLS_REGISTRY["edit_file_local"], LOCAL_TOOLS_REGISTRY["edit_file_patch_local"], LOCAL_TOOLS_REGISTRY["todo_write_local"]]
    infra = [
        LOCAL_TOOLS_REGISTRY["bash_local"], 
        LOCAL_TOOLS_REGISTRY["manage_processes_local"],
        LOCAL_TOOLS_REGISTRY["local_net_tool"]
    ]
    
    if mode == "default": return read
    if mode == "auto-approve": return read + edit + [LOCAL_TOOLS_REGISTRY["manage_processes_local"], LOCAL_TOOLS_REGISTRY["local_net_tool"]]
    if mode == "yolo": return read + edit + infra
    return read