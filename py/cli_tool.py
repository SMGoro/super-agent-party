#!/usr/bin/env python3
import asyncio
import os
import re
import shutil
import subprocess
import json
import platform
import uuid
import tempfile
from pathlib import Path
from typing import AsyncIterator
from datetime import datetime
import aiofiles
import aiofiles.os
import glob as std_glob
import fnmatch

def get_shell_environment():
    """é€šè¿‡å­è¿›ç¨‹è·å–å®Œæ•´çš„ shell ç¯å¢ƒ"""
    shell = os.environ.get('SHELL', '/bin/zsh')
    home = Path.home()
    
    config_commands = [
        f'source {home}/.zshrc && env',
        f'source {home}/.bash_profile && env', 
        f'source {home}/.bashrc && env',
        'env'
    ]
    
    for cmd in config_commands:
        try:
            result = subprocess.run(
                [shell, '-i', '-c', cmd],
                capture_output=True,
                text=True,
                timeout=5
            )
            if result.returncode == 0:
                for line in result.stdout.splitlines():
                    if '=' in line:
                        var_name, var_value = line.split('=', 1)
                        os.environ[var_name] = var_value
                print("Successfully loaded environment from shell")
                return
        except Exception as e:
            print(f"Failed to load environment with command '{cmd}': {e}")
            continue
    
    print("Warning: Could not load shell environment, using current environment")

get_shell_environment()

import anyio
from claude_agent_sdk import query, ClaudeAgentOptions, AssistantMessage, TextBlock
from py.get_setting import load_settings

# ==================== å…¬å…±å·¥å…·å‡½æ•° ====================

async def read_stream(stream, *, is_error: bool = False):
    """è¯»å–æµå¹¶æ·»åŠ é”™è¯¯å‰ç¼€"""
    if stream is None:
        return
    async for line in stream:
        prefix = "[ERROR] " if is_error else ""
        yield f"{prefix}{line.decode('utf-8', errors='replace').rstrip()}"

async def _merge_streams(*streams):
    """åˆå¹¶å¤šä¸ªå¼‚æ­¥æµ"""
    streams = [s.__aiter__() for s in streams]
    while streams:
        for stream in list(streams):
            try:
                item = await stream.__anext__()
                yield item
            except StopAsyncIteration:
                streams.remove(stream)

# ==================== Docker Sandbox åŸºç¡€è®¾æ–½ ====================

import hashlib

def get_safe_container_name(cwd: str) -> str:
    """
    æ ¹æ®è·¯å¾„ç”Ÿæˆåˆæ³•å®¹å™¨å
    è§„åˆ™ï¼šsandbox- + è·¯å¾„MD5å‰12ä½ï¼ˆç¡®ä¿å”¯ä¸€ä¸”åˆæ³•ï¼‰
    """
    abs_path = str(Path(cwd).resolve())
    path_hash = hashlib.md5(abs_path.encode()).hexdigest()[:12]
    return f"sandbox-{path_hash}"

async def get_or_create_docker_sandbox(cwd: str, image_name: str = "docker/sandbox-templates:latest") -> str:
    """
    è·å–æˆ–åˆ›å»ºåŸºäºè·¯å¾„çš„æŒä¹…åŒ–æ²™ç›’
    è¿”å›: å®¹å™¨åï¼ˆåŒæ—¶ä¹Ÿæ˜¯æ²™ç›’IDï¼‰
    """
    container_name = get_safe_container_name(cwd)
    
    check_proc = await asyncio.create_subprocess_exec(
        "docker", "ps", "-a", "--filter", f"name=^/{container_name}$", "--format", "{{.Names}}|{{.Status}}",
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    stdout, _ = await check_proc.communicate()
    output = stdout.decode().strip()
    
    if container_name in output:
        status = output.split("|")[-1] if "|" in output else ""
        
        if "Up" in status:
            print(f"[INFO] ä½¿ç”¨å·²è¿è¡Œçš„æ²™ç›’: {container_name}")
            return container_name
        else:
            print(f"[INFO] å¯åŠ¨å·²å­˜åœ¨çš„æ²™ç›’: {container_name}")
            start_proc = await asyncio.create_subprocess_exec(
                "docker", "start", container_name,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            _, stderr = await start_proc.communicate()
            if start_proc.returncode != 0:
                raise Exception(f"å¯åŠ¨æ²™ç›’å¤±è´¥: {stderr.decode()}")
            return container_name
    
    print(f"[INFO] åˆ›å»ºæ–°æ²™ç›’: {container_name} (è·¯å¾„: {cwd})")
    
    create_cmd = [
        "docker", "run", "-d",
        "--name", container_name,
        "-v", f"{cwd}:/workspace",
        "-w", "/workspace",
        "--restart", "unless-stopped",
        "--label", f"sandbox.path={cwd}",
        "--label", "sandbox.type=persistent",
        image_name,
        "tail", "-f", "/dev/null"
    ]
    
    proc = await asyncio.create_subprocess_exec(
        *create_cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    stdout, stderr = await proc.communicate()
    
    if proc.returncode == 0:
        container_id = stdout.decode().strip()[:12]
        print(f"[INFO] æ²™ç›’åˆ›å»ºæˆåŠŸ: {container_id}")
        return container_name
    else:
        error_msg = stderr.decode()
        if "is already in use by container" in error_msg:
            await asyncio.sleep(0.5)
            return await get_or_create_docker_sandbox(cwd, image_name)
        raise Exception(f"åˆ›å»ºæ²™ç›’å¤±è´¥: {error_msg}")

async def _exec_docker_cmd_simple(cwd: str, cmd_list: list) -> str:
    """
    å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼šåœ¨å®¹å™¨å†…æ‰§è¡Œç®€å•å‘½ä»¤å¹¶è·å–ä¸€æ¬¡æ€§è¾“å‡º
    """
    container_name = await get_or_create_docker_sandbox(cwd)
    
    full_cmd = ["docker", "exec", "-w", "/workspace", container_name] + cmd_list
    
    proc = await asyncio.create_subprocess_exec(
        *full_cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    stdout, stderr = await proc.communicate()
    
    if proc.returncode != 0:
        raise Exception(f"Command failed: {stderr.decode().strip()}")
    return stdout.decode()

async def _get_current_cwd() -> str:
    """å†…éƒ¨è¾…åŠ©ï¼šè·å–å½“å‰é…ç½®çš„å·¥ä½œç›®å½•"""
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    if not cwd:
        raise ValueError("No workspace directory specified in settings (CLISettings.cc_path).")
    return cwd

async def docker_sandbox_async(command: str) -> str | AsyncIterator[str]:
    """
    åœ¨æŒä¹…åŒ– Docker æ²™ç›’ä¸­æ‰§è¡Œå‘½ä»¤
    """
    settings = await load_settings()
    CLISettings = settings.get("CLISettings", {})
    cwd = CLISettings.get("cc_path")
    if not cwd:
        return "Error: No workspace directory specified in settings."
    dsSettings = settings.get("dsSettings", {})
    
    image_name = "docker/sandbox-templates:latest"
    
    if not cwd or not Path(cwd).is_dir():
        return f"Error: Invalid workspace directory: {cwd}"
    
    try:
        container_name = await get_or_create_docker_sandbox(cwd, image_name)
    except Exception as e:
        return f"Docker Sandbox Initialization Error: {str(e)}"

    async def _stream() -> AsyncIterator[str]:
        exec_cmd = [
            "docker", "exec",
            "-i",
            container_name,
            "sh", "-c",
            f"cd /workspace && {command}"
        ]
        
        output_yielded = False
        
        try:
            process = await asyncio.create_subprocess_exec(
                *exec_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )
            
            async for line in _merge_streams(
                read_stream(process.stdout, is_error=False),
                read_stream(process.stderr, is_error=True),
            ):
                yield line
                output_yielded = True
            
            await process.wait()
            
            if process.returncode != 0:
                yield f"[EXIT CODE] {process.returncode}"
            elif process.returncode == 0 and not output_yielded:
                yield "[SUCCESS] å‘½ä»¤å·²æˆåŠŸæ‰§è¡ŒæœªæŠ¥é”™"
                
        except Exception as e:
            yield f"[ERROR] æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    return _stream()

# ==================== 1. ç²¾ç¡®å­—ç¬¦ä¸²æ›¿æ¢å·¥å…· (edit_file_patch) ====================

async def edit_file_patch_tool(path: str, old_string: str, new_string: str) -> str:
    """
    [å·¥å…·] ç²¾ç¡®å­—ç¬¦ä¸²æ›¿æ¢ - Claude Code ç»å…¸åŠŸèƒ½
    æŸ¥æ‰¾ç‰¹å®šä»£ç å—å¹¶æ›¿æ¢ï¼Œä¿ç•™æ–‡ä»¶å…¶ä½™éƒ¨åˆ†å’Œæ ¼å¼
    
    ç‰¹æ€§ï¼š
    - ç²¾ç¡®åŒ¹é… old_stringï¼ˆå»é™¤è¡Œå°¾ç©ºæ ¼åè¿›è¡ŒåŒ¹é…ï¼‰
    - åªæ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹
    - å¦‚æœåŒ¹é…å¤±è´¥ï¼Œè¿”å›è¯¦ç»†é”™è¯¯ä¿¡æ¯å¸®åŠ©å®šä½
    """
    try:
        real_cwd = await _get_current_cwd()
        container_name = await get_or_create_docker_sandbox(real_cwd)
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await _exec_docker_cmd_simple(real_cwd, ["cat", path])
        
        # è§„èŒƒåŒ–è¡Œå°¾ç©ºæ ¼ç”¨äºåŒ¹é…ï¼ˆä½†ä¿ç•™åŸæ–‡ä»¶æ ¼å¼ï¼‰
        normalized_content = "\n".join(line.rstrip() for line in content.split("\n"))
        normalized_old = "\n".join(line.rstrip() for line in old_string.split("\n"))
        
        if normalized_old not in normalized_content:
            # æä¾›è¯Šæ–­ä¿¡æ¯
            lines = content.split("\n")
            first_line = old_string.split("\n")[0] if "\n" in old_string else old_string
            
            # å°è¯•æ¨¡ç³ŠæŸ¥æ‰¾ç¬¬ä¸€è¡Œ
            similar_lines = [f"Line {i+1}: {line[:80]}" for i, line in enumerate(lines) 
                           if first_line.strip() in line]
            
            error_msg = f"[Error] Old string not found in file '{path}'.\n"
            if similar_lines:
                error_msg += f"\nFound similar lines containing '{first_line[:30]}':\n" + "\n".join(similar_lines[:5])
            else:
                error_msg += f"\nFile has {len(lines)} lines. First line of your search: '{first_line[:50]}'"
            return error_msg
        
        # æ‰§è¡Œæ›¿æ¢ï¼ˆä½¿ç”¨åŸå§‹å†…å®¹ï¼‰
        new_content = content.replace(old_string, new_string, 1)
        
        # å†™å›æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
            tmp.write(new_content)
            tmp_path = tmp.name
        
        dest_path = f"{container_name}:/workspace/{path}"
        
        cp_proc = await asyncio.create_subprocess_exec(
            "docker", "cp", tmp_path, dest_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        _, stderr = await cp_proc.communicate()
        
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)
        
        if cp_proc.returncode != 0:
            return f"[Error] Patch failed: {stderr.decode()}"
        
        # æ·»åŠ è¡Œæ•°ç»Ÿè®¡ä¿¡æ¯
        old_lines = old_string.count('\n') + 1
        new_lines = new_string.count('\n') + 1
        return f"[Success] Patched '{path}' ({old_lines} lines -> {new_lines} lines)"
        
    except Exception as e:
        return f"[Error] Patch failed: {str(e)}"

# ==================== 2. Glob æ–‡ä»¶åŒ¹é…å·¥å…· (glob_files) ====================

async def glob_files_tool(pattern: str, exclude: str = "**/node_modules/**,**/.git/**,**/__pycache__/**") -> str:
    """
    [å·¥å…·] çœŸæ­£çš„ Glob æ¨¡å¼åŒ¹é…ï¼ˆé€’å½’æŸ¥æ‰¾ï¼‰
    æ”¯æŒ **/*.py ç­‰é€’å½’æ¨¡å¼ï¼Œå¼¥è¡¥äº† list_files åªèƒ½åˆ—å•å±‚ç›®å½•çš„ä¸è¶³
    
    å‚æ•°:
        pattern: glob æ¨¡å¼ï¼Œå¦‚ "**/*.py", "src/**/*.ts", "*.md"
        exclude: æ’é™¤æ¨¡å¼ï¼Œé€—å·åˆ†éš”ï¼ˆé»˜è®¤æ’é™¤ node_modules, .git, __pycache__ï¼‰
    """
    try:
        real_cwd = await _get_current_cwd()
        
        # åœ¨å®¹å™¨å†…ä½¿ç”¨ Python çš„ glob æ¨¡å—ï¼ˆæœ€å‡†ç¡®ï¼‰
        exclude_list = [e.strip() for e in exclude.split(",") if e.strip()]
        
        python_script = f'''
import glob
import os
import json

files = glob.glob("/workspace/{pattern}", recursive=True)
exclude_patterns = {exclude_list}

filtered = []
for f in files:
    if not os.path.isfile(f):
        continue
    rel_path = f.replace("/workspace/", "")
    # æ£€æŸ¥æ’é™¤æ¨¡å¼
    should_exclude = False
    for ex in exclude_patterns:
        if glob.fnmatch.fnmatch(rel_path, ex) or glob.fnmatch.fnmatch(f, ex):
            should_exclude = True
            break
    if not should_exclude:
        filtered.append(rel_path)

print(json.dumps(filtered, indent=2))
'''
        
        output = await _exec_docker_cmd_simple(real_cwd, ["python3", "-c", python_script])
        
        try:
            files = json.loads(output)
            if not files:
                return "[Result] No files found matching the pattern."
            
            # æ ¼å¼åŒ–è¾“å‡ºï¼Œå¸¦åºå·å’Œæ–‡ä»¶ç±»å‹æ ‡è¯†
            result_lines = [f"[{len(files)} files matched]"]
            for i, f in enumerate(files[:50], 1):  # é™åˆ¶æ˜¾ç¤ºå‰50ä¸ª
                icon = "ğŸ“„" if "." in f else "ğŸ“"
                if f.endswith(".py"): icon = "ğŸ"
                elif f.endswith(".js") or f.endswith(".ts"): icon = "ğŸ“œ"
                elif f.endswith(".md"): icon = "ğŸ“"
                elif f.endswith(".json"): icon = "âš™ï¸"
                result_lines.append(f"{icon} {f}")
            
            if len(files) > 50:
                result_lines.append(f"\n... and {len(files) - 50} more files")
            
            return "\n".join(result_lines)
            
        except json.JSONDecodeError:
            return f"[Result] {output}"
            
    except Exception as e:
        return f"[Error] Glob failed: {str(e)}"

# ==================== 3. ä»»åŠ¡ç®¡ç†å·¥å…· (todo_write) ====================

async def todo_write_tool(action: str, id: str = None, content: str = None, priority: str = "medium", status: str = None) -> str:
    """
    [å·¥å…·] å®Œæ•´çš„ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ
    æŒä¹…åŒ–å­˜å‚¨åœ¨ .party/ai_todos.jsonï¼Œæ”¯æŒä¼˜å…ˆçº§å’ŒçŠ¶æ€è·Ÿè¸ª
    
    æ“ä½œ:
        create: åˆ›å»ºæ–°ä»»åŠ¡ (éœ€è¦ content, å¯é€‰ priority)
        update: æ›´æ–°ä»»åŠ¡ (éœ€è¦ id, å¯é€‰ content/priority/status)
        delete: åˆ é™¤ä»»åŠ¡ (éœ€è¦ id)
        list: åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡
        toggle: åˆ‡æ¢ä»»åŠ¡å®ŒæˆçŠ¶æ€ (éœ€è¦ id)
        
    ä¼˜å…ˆçº§: high, medium, low
    çŠ¶æ€: pending, in_progress, done, cancelled
    """
    try:
        real_cwd = await _get_current_cwd()
        container_name = await get_or_create_docker_sandbox(real_cwd)
        
        todo_dir = "/workspace/.party"
        todo_file = f"{todo_dir}/ai_todos.json"
        
        # è¯»å–ç°æœ‰ todos
        try:
            content_data = await _exec_docker_cmd_simple(real_cwd, ["cat", todo_file])
            todos = json.loads(content_data)
            if not isinstance(todos, list):
                todos = []
        except Exception:
            todos = []
        
        # æ‰§è¡Œæ“ä½œ
        if action == "create":
            if not content:
                return "[Error] 'content' is required for create action"
            
            new_todo = {
                "id": id or str(uuid.uuid4())[:8],
                "content": content,
                "priority": priority if priority in ["high", "medium", "low"] else "medium",
                "status": "pending",
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "completed_at": None
            }
            todos.append(new_todo)
            
            # å†™å›æ–‡ä»¶
            json_str = json.dumps(todos, indent=2, ensure_ascii=False)
            with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
                tmp.write(json_str)
                tmp_path = tmp.name
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            await _exec_docker_cmd_simple(real_cwd, ["mkdir", "-p", todo_dir])
            
            dest_path = f"{container_name}:{todo_file}"
            cp_proc = await asyncio.create_subprocess_exec(
                "docker", "cp", tmp_path, dest_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            await cp_proc.communicate()
            os.unlink(tmp_path)
            
            return f"[Success] Created todo [{new_todo['id']}]: {content}"
            
        elif action == "list":
            if not todos:
                return "[Result] No todos found. Create one with action='create'"
            
            # æŒ‰ä¼˜å…ˆçº§å’ŒçŠ¶æ€æ’åº
            priority_order = {"high": 0, "medium": 1, "low": 2}
            sorted_todos = sorted(todos, key=lambda x: (priority_order.get(x.get('priority', 'medium'), 1), 
                                                        x.get('status', 'pending') != 'pending'))
            
            lines = ["ğŸ“‹ Task List:", "â”€" * 50]
            for t in sorted_todos:
                status_icon = {"pending": "â³", "in_progress": "ğŸ”„", "done": "âœ…", "cancelled": "âŒ"}.get(t.get('status'), "â³")
                priority_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(t.get('priority'), "ğŸŸ¡")
                lines.append(f"{status_icon} [{t['id']}] {t['content'][:40]} {priority_icon}")
                if len(t['content']) > 40:
                    lines.append(f"    ...{t['content'][40:]}")
            
            lines.append("â”€" * 50)
            lines.append(f"Total: {len(todos)} tasks ({sum(1 for t in todos if t.get('status') != 'done')} pending)")
            return "\n".join(lines)
            
        elif action == "update":
            if not id:
                return "[Error] 'id' is required for update action"
            
            found = False
            for todo in todos:
                if todo["id"] == id:
                    if content:
                        todo["content"] = content
                    if priority and priority in ["high", "medium", "low"]:
                        todo["priority"] = priority
                    if status and status in ["pending", "in_progress", "done", "cancelled"]:
                        todo["status"] = status
                        if status == "done" and not todo.get("completed_at"):
                            todo["completed_at"] = datetime.now().isoformat()
                    todo["updated_at"] = datetime.now().isoformat()
                    found = True
                    break
            
            if not found:
                return f"[Error] Todo with id '{id}' not found. Use action='list' to see all ids."
            
            # å†™å›
            json_str = json.dumps(todos, indent=2, ensure_ascii=False)
            with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
                tmp.write(json_str)
                tmp_path = tmp.name
            
            dest_path = f"{container_name}:{todo_file}"
            await asyncio.create_subprocess_exec("docker", "cp", tmp_path, dest_path,
                                                stdout=asyncio.subprocess.PIPE, 
                                                stderr=asyncio.subprocess.PIPE)
            os.unlink(tmp_path)
            
            return f"[Success] Updated todo [{id}]"
            
        elif action == "delete":
            if not id:
                return "[Error] 'id' is required for delete action"
            
            original_len = len(todos)
            todos = [t for t in todos if t["id"] != id]
            
            if len(todos) == original_len:
                return f"[Error] Todo with id '{id}' not found."
            
            # å†™å›
            json_str = json.dumps(todos, indent=2, ensure_ascii=False)
            with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
                tmp.write(json_str)
                tmp_path = tmp.name
            
            dest_path = f"{container_name}:{todo_file}"
            await asyncio.create_subprocess_exec("docker", "cp", tmp_path, dest_path,
                                                stdout=asyncio.subprocess.PIPE,
                                                stderr=asyncio.subprocess.PIPE)
            os.unlink(tmp_path)
            
            return f"[Success] Deleted todo [{id}]"
            
        elif action == "toggle":
            if not id:
                return "[Error] 'id' is required for toggle action"
            
            for todo in todos:
                if todo["id"] == id:
                    if todo.get("status") == "done":
                        todo["status"] = "pending"
                        todo["completed_at"] = None
                        msg = "marked as pending"
                    else:
                        todo["status"] = "done"
                        todo["completed_at"] = datetime.now().isoformat()
                        msg = "completed"
                    
                    todo["updated_at"] = datetime.now().isoformat()
                    
                    # å†™å›
                    json_str = json.dumps(todos, indent=2, ensure_ascii=False)
                    with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
                        tmp.write(json_str)
                        tmp_path = tmp.name
                    
                    dest_path = f"{container_name}:{todo_file}"
                    await asyncio.create_subprocess_exec("docker", "cp", tmp_path, dest_path,
                                                        stdout=asyncio.subprocess.PIPE,
                                                        stderr=asyncio.subprocess.PIPE)
                    os.unlink(tmp_path)
                    
                    return f"[Success] Todo [{id}] {msg} âœ…"
            
            return f"[Error] Todo with id '{id}' not found."
            
        else:
            return f"[Error] Unknown action: {action}. Use: create, list, update, delete, toggle"
            
    except Exception as e:
        return f"[Error] Todo operation failed: {str(e)}"

# ==================== å·¥å…·æ³¨å†Œä¸æƒé™ç®¡ç† ====================

TOOLS_REGISTRY = {
    # --- åªè¯»å·¥å…· ---
    "list_files": {
        "type": "function",
        "function": {
            "name": "list_files_tool",
            "description": "List files and directories in the workspace.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "The directory path (default: .)"},
                    "show_all": {"type": "boolean", "description": "Show hidden files (default: false)"}
                }
            }
        }
    },
    "read_file": {
        "type": "function",
        "function": {
            "name": "read_file_tool",
            "description": "Read the contents of a file with line numbers.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "The path to the file"}
                },
                "required": ["path"]
            }
        }
    },
    "search_files": {
        "type": "function",
        "function": {
            "name": "search_files_tool",
            "description": "Search for a text pattern recursively in files using grep.",
            "parameters": {
                "type": "object",
                "properties": {
                    "pattern": {"type": "string", "description": "The regex or text to search for"},
                    "path": {"type": "string", "description": "Directory to search in (default: .)"}
                },
                "required": ["pattern"]
            }
        }
    },
    "glob_files": {
        "type": "function",
        "function": {
            "name": "glob_files_tool",
            "description": "Find files using glob patterns (e.g., '**/*.py' for all Python files recursively). Much more powerful than list_files for finding specific file types across the project.",
            "parameters": {
                "type": "object",
                "properties": {
                    "pattern": {
                        "type": "string", 
                        "description": "Glob pattern like '**/*.py', 'src/**/*.ts', '*.md', 'test_*.py'"
                    },
                    "exclude": {
                        "type": "string",
                        "description": "Comma-separated exclusion patterns (default: '**/node_modules/**,**/.git/**')"
                    }
                },
                "required": ["pattern"]
            }
        }
    },
    
    # --- ç¼–è¾‘å·¥å…· ---
    "edit_file": {
        "type": "function",
        "function": {
            "name": "edit_file_tool",
            "description": "Create or Overwrite a file with new content. For editing, read the file first, then provide the FULL new content.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "The file path"},
                    "content": {"type": "string", "description": "The full content to write to the file"}
                },
                "required": ["path", "content"]
            }
        }
    },
    "edit_file_patch": {
        "type": "function",
        "function": {
            "name": "edit_file_patch_tool",
            "description": "Precise string replacement - the classic Claude Code feature. Finds a specific code block (old_string) and replaces it with new_string, preserving the rest of the file. Safer than edit_file for modifications. old_string must match exactly (except trailing whitespace).",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {
                        "type": "string",
                        "description": "Path to the file to edit"
                    },
                    "old_string": {
                        "type": "string",
                        "description": "The exact code block to replace (can be multiple lines). Must match the file content precisely."
                    },
                    "new_string": {
                        "type": "string",
                        "description": "The new code block to insert in place of old_string"
                    }
                },
                "required": ["path", "old_string", "new_string"]
            }
        }
    },
    
    # --- ä»»åŠ¡ç®¡ç†å·¥å…· ---
    "todo_write": {
        "type": "function",
        "function": {
            "name": "todo_write_tool",
            "description": "Task management system with persistent storage in .party/ai_todos.json. CRUD operations for project tasks with priorities and status tracking. Actions: create (needs content), list, update (needs id), delete (needs id), toggle (toggle done status).",
            "parameters": {
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "enum": ["create", "list", "update", "delete", "toggle"],
                        "description": "Operation to perform"
                    },
                    "id": {
                        "type": "string",
                        "description": "Task ID (required for update/delete/toggle, optional for create)"
                    },
                    "content": {
                        "type": "string",
                        "description": "Task description (required for create, optional for update)"
                    },
                    "priority": {
                        "type": "string",
                        "enum": ["high", "medium", "low"],
                        "description": "Task priority (default: medium)"
                    },
                    "status": {
                        "type": "string",
                        "enum": ["pending", "in_progress", "done", "cancelled"],
                        "description": "Task status (for update action)"
                    }
                },
                "required": ["action"]
            }
        }
    },
    
    # --- å…¨æƒé™å·¥å…· (Bash) ---
    "bash": {
        "type": "function",
        "function": {
            "name": "docker_sandbox_async", 
            "description": "Execute a bash command in the terminal. Use this for running scripts, installing packages, or git operations.",
            "parameters": {
                "type": "object",
                "properties": {
                    "command": {"type": "string", "description": "The bash command"}
                },
                "required": ["command"]
            }
        }
    }
}

def get_tools_for_mode(mode: str) -> list:
    """
    æ ¹æ®æƒé™æ¨¡å¼è¿”å›å·¥å…·å®šä¹‰åˆ—è¡¨
    
    æƒé™çŸ©é˜µ:
    - default (Default Permission Mode): åªè¯»å·¥å…·
    - auto-approve (Accept Edits): åªè¯» + æ–‡ä»¶ç¼–è¾‘ + ä»»åŠ¡ç®¡ç†  
    - yolo (Bypass Permissions): å…¨éƒ¨å·¥å…·ï¼ˆåŒ…æ‹¬ bashï¼‰
    """
    
    # åŸºç¡€åªè¯»é›†
    read_only_tools = [
        TOOLS_REGISTRY["list_files"],
        TOOLS_REGISTRY["read_file"],
        TOOLS_REGISTRY["search_files"],
        TOOLS_REGISTRY["glob_files"]  # æ–°å¢ï¼šé€’å½’æ–‡ä»¶æŸ¥æ‰¾ï¼ˆåªè¯»ï¼‰
    ]
    
    # ç¼–è¾‘é›† (æ–‡ä»¶ä¿®æ”¹)
    edit_tools = [
        TOOLS_REGISTRY["edit_file"],
        TOOLS_REGISTRY["edit_file_patch"]  # æ–°å¢ï¼šç²¾ç¡®å­—ç¬¦ä¸²æ›¿æ¢ï¼ˆæ¯”å…¨é‡è¦†ç›–æ›´å®‰å…¨ï¼‰
    ]
    
    # ä»»åŠ¡ç®¡ç†é›† (å…ƒæ•°æ®æ“ä½œï¼Œç†è®ºä¸Šå®‰å…¨ï¼Œä½†æ¶‰åŠæ–‡ä»¶å†™å…¥)
    todo_tools = [
        TOOLS_REGISTRY["todo_write"]  # æ–°å¢ï¼šä»»åŠ¡ç®¡ç†ç³»ç»Ÿ
    ]
    
    # ç»ˆç«¯é›† (å±é™©æ“ä½œ)
    terminal_tools = [
        TOOLS_REGISTRY["bash"]
    ]
    
    if mode == "default":
        # é»˜è®¤æ¨¡å¼ï¼šåªèƒ½æµè§ˆå’Œæœç´¢
        return read_only_tools
        
    elif mode == "auto-approve": 
        # è‡ªåŠ¨æ‰¹å‡†æ¨¡å¼ï¼šå¯ä»¥è¯»å†™æ–‡ä»¶å’Œç®¡ç†ä»»åŠ¡ï¼Œä½†ä¸èƒ½æ‰§è¡Œä»»æ„ bash
        return read_only_tools + edit_tools + todo_tools
        
    elif mode == "yolo":
        # å®Œå…¨æˆæƒæ¨¡å¼ï¼šæ‰€æœ‰å·¥å…·
        return read_only_tools + edit_tools + todo_tools + terminal_tools
    
    else:
        # æœªçŸ¥æ¨¡å¼ï¼Œè¿”å›æœ€å®‰å…¨é€‰é¡¹
        return read_only_tools

# ==================== å…¶ä»–åŸæœ‰å·¥å…·å‡½æ•° ====================

async def read_file_tool(path: str) -> str:
    """[å·¥å…·] è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå¸¦æœ‰è¡Œå·"""
    try:
        real_cwd = await _get_current_cwd()
        cmd = ["cat", "-n", path] 
        output = await _exec_docker_cmd_simple(real_cwd, cmd)
        return output
    except Exception as e:
        return f"[Error] Could not read file: {str(e)}"

async def edit_file_tool(path: str, content: str) -> str:
    """[å·¥å…·] è¦†ç›–å†™å…¥æ–‡ä»¶"""
    try:
        real_cwd = await _get_current_cwd()
        container_name = await get_or_create_docker_sandbox(real_cwd)
        
        with tempfile.NamedTemporaryFile(mode='w', delete=False, encoding='utf-8') as tmp:
            tmp.write(content)
            tmp_path = tmp.name
        
        dir_name = os.path.dirname(path)
        if dir_name:
            await _exec_docker_cmd_simple(real_cwd, ["mkdir", "-p", dir_name])

        dest_path = f"{container_name}:/workspace/{path}"
        
        cp_proc = await asyncio.create_subprocess_exec(
            "docker", "cp", tmp_path, dest_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        _, stderr = await cp_proc.communicate()
        
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)
        
        if cp_proc.returncode != 0:
            return f"[Error] Save failed: {stderr.decode()}"
            
        return f"[Success] File '{path}' saved successfully."
    except Exception as e:
        return f"[Error] Edit tool failed: {str(e)}"

async def search_files_tool(pattern: str, path: str = ".") -> str:
    """[å·¥å…·] ä½¿ç”¨ grep æœç´¢æ–‡ä»¶å†…å®¹"""
    try:
        real_cwd = await _get_current_cwd()
        cmd = ["grep", "-rn", pattern, path]
        output = await _exec_docker_cmd_simple(real_cwd, cmd)
        return output if output else "[Result] No matches found."
    except Exception as e:
        return f"[Error] Search failed: {str(e)}"

async def list_files_tool(path: str = ".", show_all: bool = False) -> str:
    """[å·¥å…·] åˆ—å‡ºç›®å½•ä¸‹çš„æ–‡ä»¶
    å‚æ•°:
        show_all: æ˜¯å¦æ˜¾ç¤ºéšè—æ–‡ä»¶ï¼ˆé»˜è®¤Falseï¼‰
    """
    try:
        real_cwd = await _get_current_cwd()
        
        # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰éšè—æ–‡ä»¶
        all_files = await _exec_docker_cmd_simple(real_cwd, ["ls", "-A", path])
        has_hidden = any(f.startswith('.') for f in all_files.split('\n') if f)
        
        if show_all:
            cmd = ["ls", "-laF", path]
            output = await _exec_docker_cmd_simple(real_cwd, cmd)
            if not output:
                if has_hidden:
                    return "[Result] å½“å‰ç›®å½•æ²¡æœ‰å¯è§æ–‡ä»¶ï¼Œä½†åŒ…å«éšè—é¡¹ç›®ï¼ˆå¦‚ .party, .git ç­‰ï¼‰ã€‚å¦‚éœ€æŸ¥çœ‹è¯·ä½¿ç”¨ show_all=true"
                else:
                    return "[Result] Directory is empty."
            return output
        else:
            # é»˜è®¤ä¸æ˜¾ç¤ºéšè—æ–‡ä»¶
            cmd = ["ls", "-F", path]
            output = await _exec_docker_cmd_simple(real_cwd, cmd)
            
            if not output:
                if has_hidden:
                    return "[Result] å½“å‰ç›®å½•æ²¡æœ‰å¯è§æ–‡ä»¶ï¼Œä½†åŒ…å«éšè—é¡¹ç›®ï¼ˆå¦‚ .party, .git ç­‰ï¼‰ã€‚å¦‚éœ€æŸ¥çœ‹è¯·ä½¿ç”¨ show_all=true"
                else:
                    return "[Result] Directory is empty."
            return output
            
    except Exception as e:
        return f"[Error] {str(e)}"



class LocalEnvConfig:
    """æœ¬åœ°ç¯å¢ƒé…ç½®ç®¡ç†"""
    def __init__(self):
        self.permission_mode = "default"
        self.workspace = ""
    
    @classmethod
    async def from_settings(cls) -> "LocalEnvConfig":
        """ä»è®¾ç½®åŠ è½½é…ç½®"""
        config = cls()
        settings = await load_settings()
        cli_settings = settings.get("CLISettings", {})
        local_settings = settings.get("localEnvSettings", {})
        
        config.workspace = cli_settings.get("cc_path", "")
        config.permission_mode = local_settings.get("permissionMode", "default")
        return config

def get_safe_workspace_path(cwd: str, sub_path: str = "") -> Path:
    """
    å®‰å…¨çš„è·¯å¾„è§£æï¼šç¡®ä¿æ‰€æœ‰æ“ä½œéƒ½åœ¨å·¥ä½œç©ºé—´å†…
    é˜²æ­¢è·¯å¾„éå†æ”»å‡» (Path Traversal)
    """
    base = Path(cwd).resolve()
    if sub_path:
        target = (base / sub_path).resolve()
        try:
            target.relative_to(base)
            return target
        except ValueError:
            raise PermissionError(f"Path '{sub_path}' is outside of workspace '{cwd}'")
    return base

# ==================== æµå¤„ç†å·¥å…·ï¼ˆå¤ç”¨ï¼‰====================

async def read_stream_local(stream, *, is_error: bool = False):
    """è¯»å–æµå¹¶æ·»åŠ é”™è¯¯å‰ç¼€"""
    if stream is None:
        return
    async for line in stream:
        prefix = "[ERROR] " if is_error else ""
        yield f"{prefix}{line.decode('utf-8', errors='replace').rstrip()}"

async def _merge_streams_local(*streams):
    """åˆå¹¶å¤šä¸ªå¼‚æ­¥æµ"""
    streams = [s.__aiter__() for s in streams]
    while streams:
        for stream in list(streams):
            try:
                item = await stream.__anext__()
                yield item
            except StopAsyncIteration:
                streams.remove(stream)

async def _get_current_cwd_local() -> str:
    """è·å–å½“å‰é…ç½®çš„å·¥ä½œç›®å½•"""
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    if not cwd:
        raise ValueError("No workspace directory specified in settings (CLISettings.cc_path).")
    if not Path(cwd).is_dir():
        raise ValueError(f"Workspace directory does not exist: {cwd}")
    return cwd

# ==================== çº¯è·¨å¹³å°æœ¬åœ°ç¯å¢ƒå·¥å…· ====================

async def _get_current_cwd_local() -> str:
    """è·å–å½“å‰é…ç½®çš„å·¥ä½œç›®å½•ï¼ˆè·¨å¹³å°ï¼‰"""
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    if not cwd:
        raise ValueError("No workspace directory specified in settings (CLISettings.cc_path).")
    
    # è·¨å¹³å°è·¯å¾„å¤„ç†
    cwd_path = Path(cwd).resolve()
    if not cwd_path.exists():
        raise ValueError(f"Workspace directory does not exist: {cwd}")
    return str(cwd_path)

def get_safe_workspace_path(cwd: str, sub_path: str = "") -> Path:
    """å®‰å…¨çš„è·¯å¾„è§£æï¼ˆè·¨å¹³å°ï¼‰"""
    base = Path(cwd).resolve()
    if sub_path:
        # æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦ï¼ˆWindows ä½¿ç”¨ \ï¼ŒUnix ä½¿ç”¨ /ï¼‰
        target = (base / sub_path).resolve()
        try:
            # ç¡®ä¿ç›®æ ‡è·¯å¾„åœ¨å·¥ä½œç©ºé—´å†…
            target.relative_to(base)
            return target
        except ValueError:
            raise PermissionError(f"Path '{sub_path}' is outside of workspace '{cwd}'")
    return base

async def read_todos_local(cwd: str) -> list:
    """è¯»å–æœ¬åœ°å¾…åŠäº‹é¡¹ï¼ˆè·¨å¹³å°ï¼Œä¸ä¾èµ–å¤–éƒ¨å‘½ä»¤ï¼‰"""
    todo_file = Path(cwd) / ".party" / "ai_todos.json"
    if not todo_file.exists():
        return []
    
    try:
        async with aiofiles.open(todo_file, 'r', encoding='utf-8') as f:
            content = await f.read()
            if not content.strip():
                return []
            return json.loads(content)
    except (json.JSONDecodeError, FileNotFoundError):
        return []
    except Exception as e:
        print(f"[Todo Loader] Error reading todos: {e}")
        return []

# 1. è·¨å¹³å°æœç´¢å·¥å…·ï¼ˆä¸ä¾èµ– grep/rgï¼‰
async def search_files_tool_local(pattern: str, path: str = ".") -> str:
    """
    [æœ¬åœ°ç¯å¢ƒ-è·¨å¹³å°] é€’å½’æœç´¢æ–‡ä»¶å†…å®¹
    ä½¿ç”¨ Python åŸç”Ÿå®ç°ï¼Œä¸ä¾èµ–ç³»ç»Ÿ grep å‘½ä»¤
    """
    try:
        cwd = await _get_current_cwd_local()
        target_dir = get_safe_workspace_path(cwd, path)
        
        matches = []
        compiled_pattern = re.compile(pattern)
        
        # é€’å½’éå†ç›®å½•
        for root, dirs, files in os.walk(target_dir):
            # è·³è¿‡éšè—ç›®å½•å’Œå¸¸è§ä¾èµ–ç›®å½•ï¼ˆè·¨å¹³å°ï¼‰
            dirs[:] = [d for d in dirs if not d.startswith('.') and 
                      d not in ['__pycache__', 'node_modules', 'venv', '.git', 'dist', 'build']]
            
            for file in files:
                if file.startswith('.'):
                    continue
                    
                file_path = Path(root) / file
                
                # åªæœç´¢æ–‡æœ¬æ–‡ä»¶ï¼Œè·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶
                try:
                    # å¼‚æ­¥è¯»å–æ–‡ä»¶
                    async with aiofiles.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = await f.read()
                        
                    lines = content.splitlines()
                    for i, line in enumerate(lines, 1):
                        if compiled_pattern.search(line):
                            rel_path = file_path.relative_to(target_dir)
                            matches.append(f"{rel_path}:{i}:{line.strip()}")
                            
                            # é™åˆ¶ç»“æœæ•°é‡ï¼Œé¿å…è¿”å›è¿‡å¤š
                            if len(matches) >= 100:
                                break
                    if len(matches) >= 100:
                        break
                        
                except (IOError, OSError):
                    continue
            
            if len(matches) >= 100:
                break
        
        if not matches:
            return "[Result] No matches found."
        
        result = "\n".join(matches[:100])
        if len(matches) >= 100:
            result += "\n[Note] More than 100 matches found, showing first 100."
        return result
        
    except Exception as e:
        return f"[Error] Search failed: {str(e)}"

# 2. è·¨å¹³å° Bash å·¥å…·ï¼ˆè‡ªåŠ¨é€‚é…æ“ä½œç³»ç»Ÿï¼‰
async def bash_tool_local(command: str) -> str | AsyncIterator[str]:
    """
    [æœ¬åœ°ç¯å¢ƒ-è·¨å¹³å°] æ‰§è¡Œå‘½ä»¤
    Windows ä½¿ç”¨ cmdï¼ŒmacOS/Linux ä½¿ç”¨ bash/sh
    """
    settings = await load_settings()
    cwd = settings.get("CLISettings", {}).get("cc_path")
    local_settings = settings.get("localEnvSettings", {})
    permission_mode = local_settings.get("permissionMode", "default")
    
    if not cwd:
        return "Error: No workspace directory specified in settings."
    
    cwd_path = Path(cwd)
    if not cwd_path.exists():
        return f"Error: Invalid workspace directory: {cwd}"
    
    # å®‰å…¨é™åˆ¶ï¼ˆè·¨å¹³å°ï¼‰
    dangerous_patterns = [
        r'rm\s+-rf\s+/[^ ]*$',  # rm -rf /something
        r'mkfs\.',               # æ ¼å¼åŒ–
        r'dd\s+if=',             # dd æ“ä½œ
        r'>\s*/dev/sda',         # å†™å…¥ç£ç›˜
        r'format\s+[a-zA-Z]:',   # Windows æ ¼å¼åŒ–
        r'del\s+/[fq]',          # Windows å¼ºåˆ¶åˆ é™¤
    ]
    
    if permission_mode != "yolo":
        for pattern in dangerous_patterns:
            if re.search(pattern, command, re.IGNORECASE):
                return f"[Error] Dangerous command blocked in '{permission_mode}' mode: {command[:50]}..."
    
    # æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹© shell
    system = platform.system()
    
    if system == "Windows":
        # Windows: ä½¿ç”¨ cmd æˆ– PowerShell
        # æ£€æµ‹æ˜¯å¦ä½¿ç”¨ PowerShell å‘½ä»¤
        if any(cmd in command.lower() for cmd in ['get-', 'set-', 'write-', '|', 'select-object', 'where-object']):
            # PowerShell å‘½ä»¤
            executable = "powershell.exe"
            args = ["-Command", command]
        else:
            # CMD å‘½ä»¤
            executable = "cmd.exe"
            args = ["/c", command]
    else:
        # macOS/Linux: ä½¿ç”¨ sh æˆ– bash
        shell = os.environ.get('SHELL', '/bin/bash')
        executable = shell
        args = ["-c", command]
    
    async def _stream() -> AsyncIterator[str]:
        try:
            process = await asyncio.create_subprocess_exec(
                executable,
                *args,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=str(cwd_path),
                env=os.environ.copy()
            )
            
            output_yielded = False
            
            # ä½¿ç”¨é€šç”¨çš„ read_stream å‡½æ•°
            async for line in _merge_streams(
                read_stream(process.stdout, is_error=False),
                read_stream(process.stderr, is_error=True),
            ):
                yield line
                output_yielded = True
            
            await process.wait()
            
            if process.returncode != 0:
                yield f"[EXIT CODE] {process.returncode}"
            elif process.returncode == 0 and not output_yielded:
                yield "[SUCCESS] Command executed successfully (no output)"
                
        except Exception as e:
            yield f"[ERROR] Execution failed: {str(e)}"
    
    return _stream()

# 3. è·¨å¹³å°æ–‡ä»¶åˆ—è¡¨ï¼ˆä¿®å¤å¯æ‰§è¡Œæ–‡ä»¶æ£€æµ‹ï¼‰
async def list_files_tool_local(path: str = ".", show_all: bool = False) -> str:
    """
    [æœ¬åœ°ç¯å¢ƒ-è·¨å¹³å°] åˆ—å‡ºç›®å½•å†…å®¹
    é€‚é… Windows å’Œ Unix çš„å¯æ‰§è¡Œæ–‡ä»¶æ£€æµ‹
    """
    try:
        cwd = await _get_current_cwd_local()
        target_dir = get_safe_workspace_path(cwd, path)
        
        entries = []
        
        # ä½¿ç”¨ Path è¿­ä»£ï¼ˆè·¨å¹³å°ï¼‰
        for entry in target_dir.iterdir():
            # éšè—æ–‡ä»¶å¤„ç†
            if not show_all and entry.name.startswith('.'):
                continue
            
            suffix = ""
            try:
                if entry.is_dir():
                    suffix = "/"
                elif entry.is_symlink():
                    suffix = "@"
                elif entry.is_file():
                    # è·¨å¹³å°å¯æ‰§è¡Œæ–‡ä»¶æ£€æµ‹
                    if _is_executable(entry):
                        suffix = "*"
            except OSError:
                # æŸäº›æ–‡ä»¶å¯èƒ½æ— æ³•è®¿é—®ï¼ˆæƒé™é—®é¢˜ï¼‰
                continue
            
            entries.append(f"{entry.name}{suffix}")
        
        if not entries:
            # æ£€æŸ¥æ˜¯å¦æœ‰éšè—æ–‡ä»¶
            try:
                has_hidden = any(e.name.startswith('.') for e in target_dir.iterdir() if e.is_file() or e.is_dir())
                if has_hidden and not show_all:
                    return "[Result] å½“å‰ç›®å½•æ²¡æœ‰å¯è§æ–‡ä»¶ï¼Œä½†åŒ…å«éšè—é¡¹ç›®ã€‚å¦‚éœ€æŸ¥çœ‹è¯·ä½¿ç”¨ show_all=true"
            except:
                pass
            return "[Result] Directory is empty."
        
        # æ’åºï¼šç›®å½•åœ¨å‰ï¼Œæ–‡ä»¶åœ¨åï¼ŒæŒ‰å­—æ¯é¡ºåºï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        entries.sort(key=lambda x: (
            not x.endswith('/'),  # ç›®å½•åœ¨å‰
            x.lower().rstrip('*@/')  # ä¸åŒºåˆ†å¤§å°å†™ï¼Œå»æ‰æ ‡è®°ç¬¦åæ’åº
        ))
        
        return "\n".join(entries)
            
    except Exception as e:
        return f"[Error] {str(e)}"

def _is_executable(file_path: Path) -> bool:
    """
    è·¨å¹³å°å¯æ‰§è¡Œæ–‡ä»¶æ£€æµ‹
    """
    try:
        if platform.system() == "Windows":
            # Windows: æ£€æŸ¥æ‰©å±•å
            executable_extensions = {'.exe', '.bat', '.cmd', '.ps1', '.py', '.sh', '.com'}
            return file_path.suffix.lower() in executable_extensions
        else:
            # Unix/Linux/macOS: ä½¿ç”¨ os.access
            return os.access(file_path, os.X_OK)
    except:
        return False

# 4. è¯»å–æ–‡ä»¶ï¼ˆå·²ç»æ˜¯è·¨å¹³å°çš„ï¼Œåªéœ€ç¡®ä¿ç¼–ç å¤„ç†ï¼‰
async def read_file_tool_local(path: str) -> str:
    """[æœ¬åœ°ç¯å¢ƒ] è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆè·¨å¹³å°ï¼‰"""
    try:
        cwd = await _get_current_cwd_local()
        safe_path = get_safe_workspace_path(cwd, path)
        
        lines = []
        async with aiofiles.open(safe_path, 'r', encoding='utf-8', errors='replace') as f:
            content = await f.read()
            
        for i, line in enumerate(content.splitlines(), 1):
            lines.append(f"{i:6}\t{line.rstrip()}")
        
        return "\n".join(lines) if lines else "[Result] File is empty."
    except Exception as e:
        return f"[Error] Could not read file: {str(e)}"

# 5. å†™å…¥æ–‡ä»¶ï¼ˆå·²ç»æ˜¯è·¨å¹³å°çš„ï¼‰
async def edit_file_tool_local(path: str, content: str) -> str:
    """[æœ¬åœ°ç¯å¢ƒ-è·¨å¹³å°] å†™å…¥æ–‡ä»¶"""
    try:
        cwd = await _get_current_cwd_local()
        safe_path = get_safe_workspace_path(cwd, path)
        
        # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨ï¼ˆè·¨å¹³å°ï¼‰
        await aiofiles.os.makedirs(safe_path.parent, exist_ok=True)
        
        async with aiofiles.open(safe_path, 'w', encoding='utf-8') as f:
            await f.write(content)
            
        return f"[Success] File '{path}' saved successfully."
    except Exception as e:
        return f"[Error] Edit tool failed: {str(e)}"

# 6. Glob å·¥å…·ï¼ˆå·²ç»æ˜¯è·¨å¹³å°çš„ï¼Œä½¿ç”¨æ ‡å‡†åº“ globï¼‰
async def glob_files_tool_local(pattern: str, exclude: str = "**/node_modules/**,**/.git/**,**/__pycache__/**") -> str:
    """[æœ¬åœ°ç¯å¢ƒ-è·¨å¹³å°] Glob æ–‡ä»¶åŒ¹é…"""
    try:
        cwd = await _get_current_cwd_local()
        base_path = Path(cwd)
        
        exclude_list = [e.strip() for e in exclude.split(",") if e.strip()]
        
        # ä½¿ç”¨æ ‡å‡†åº“ globï¼ˆå·²ç»æ˜¯è·¨å¹³å°çš„ï¼‰
        full_pattern = str(base_path / pattern)
        files = std_glob.glob(full_pattern, recursive=True)
        
        filtered = []
        for f in files:
            p = Path(f)
            if not p.is_file():
                continue
            
            try:
                rel_path = str(p.relative_to(base_path))
            except ValueError:
                continue
            
            # æ£€æŸ¥æ’é™¤æ¨¡å¼
            should_exclude = False
            for ex in exclude_list:
                if fnmatch.fnmatch(rel_path, ex) or fnmatch.fnmatch(f, ex):
                    should_exclude = True
                    break
            
            if not should_exclude:
                filtered.append(rel_path)
        
        if not filtered:
            return "[Result] No files found matching the pattern."
        
        # æ ¼å¼åŒ–è¾“å‡º
        result_lines = [f"[{len(filtered)} files matched]"]
        for i, f in enumerate(filtered[:50], 1):
            icon = "ğŸ“„"
            if f.endswith(".py"): icon = "ğŸ"
            elif f.endswith(".js") or f.endswith(".ts"): icon = "ğŸ“œ"
            elif f.endswith(".md"): icon = "ğŸ“"
            elif f.endswith(".json"): icon = "âš™ï¸"
            result_lines.append(f"{icon} {f}")
        
        if len(filtered) > 50:
            result_lines.append(f"\n... and {len(filtered) - 50} more files")
        
        return "\n".join(result_lines)
        
    except Exception as e:
        return f"[Error] Glob failed: {str(e)}"

# 7. ç²¾ç¡®æ›¿æ¢å·¥å…·ï¼ˆå·²ç»æ˜¯è·¨å¹³å°çš„ï¼‰
async def edit_file_patch_tool_local(path: str, old_string: str, new_string: str) -> str:
    """[æœ¬åœ°ç¯å¢ƒ-è·¨å¹³å°] ç²¾ç¡®å­—ç¬¦ä¸²æ›¿æ¢"""
    try:
        cwd = await _get_current_cwd_local()
        safe_path = get_safe_workspace_path(cwd, path)
        
        async with aiofiles.open(safe_path, 'r', encoding='utf-8', errors='replace') as f:
            content = await f.read()
        
        # è§„èŒƒåŒ–è¡Œå°¾ç©ºæ ¼ç”¨äºåŒ¹é…
        normalized_content = "\n".join(line.rstrip() for line in content.split("\n"))
        normalized_old = "\n".join(line.rstrip() for line in old_string.split("\n"))
        
        if normalized_old not in normalized_content:
            lines = content.split("\n")
            first_line = old_string.split("\n")[0] if "\n" in old_string else old_string
            
            similar_lines = [f"Line {i+1}: {line[:80]}" for i, line in enumerate(lines) 
                           if first_line.strip() in line]
            
            error_msg = f"[Error] Old string not found in file '{path}'.\n"
            if similar_lines:
                error_msg += f"\nFound similar lines containing '{first_line[:30]}':\n" + "\n".join(similar_lines[:5])
            else:
                error_msg += f"\nFile has {len(lines)} lines. First line of your search: '{first_line[:50]}'"
            return error_msg
        
        new_content = content.replace(old_string, new_string, 1)
        
        async with aiofiles.open(safe_path, 'w', encoding='utf-8') as f:
            await f.write(new_content)
        
        old_lines = old_string.count('\n') + 1
        new_lines = new_string.count('\n') + 1
        return f"[Success] Patched '{path}' ({old_lines} lines -> {new_lines} lines)"
        
    except Exception as e:
        return f"[Error] Patch failed: {str(e)}"

# 8. å¾…åŠäº‹é¡¹å·¥å…·ï¼ˆå·²ç»æ˜¯è·¨å¹³å°çš„ï¼‰
async def todo_write_tool_local(action: str, id: str = None, content: str = None, priority: str = "medium", status: str = None) -> str:
    """[æœ¬åœ°ç¯å¢ƒ-è·¨å¹³å°] ä»»åŠ¡ç®¡ç†"""
    try:
        cwd = await _get_current_cwd_local()
        party_dir = Path(cwd) / ".party"
        todo_file = party_dir / "ai_todos.json"
        
        # åˆ›å»ºç›®å½•ï¼ˆè·¨å¹³å°ï¼‰
        await aiofiles.os.makedirs(party_dir, exist_ok=True)
        
        # è¯»å–
        todos = await read_todos_local(cwd)
        if not isinstance(todos, list):
            todos = []
        
        # å¤„ç†å„ç§æ“ä½œï¼ˆä¸ä¹‹å‰ç›¸åŒï¼Œä½¿ç”¨çº¯ Python æ–‡ä»¶æ“ä½œï¼‰
        if action == "create":
            if not content:
                return "[Error] 'content' is required for create action"
            
            new_todo = {
                "id": id or str(uuid.uuid4())[:8],
                "content": content,
                "priority": priority if priority in ["high", "medium", "low"] else "medium",
                "status": "pending",
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "completed_at": None
            }
            todos.append(new_todo)
            
            async with aiofiles.open(todo_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(todos, indent=2, ensure_ascii=False))
            
            return f"[Success] Created todo [{new_todo['id']}]: {content}"
            
        elif action == "list":
            if not todos:
                return "[Result] No todos found. Create one with action='create'"
            
            priority_order = {"high": 0, "medium": 1, "low": 2}
            sorted_todos = sorted(todos, key=lambda x: (priority_order.get(x.get('priority', 'medium'), 1), 
                                                        x.get('status', 'pending') != 'pending'))
            
            lines = ["ğŸ“‹ Task List:", "â”€" * 50]
            for t in sorted_todos:
                status_icon = {"pending": "â³", "in_progress": "ğŸ”„", "done": "âœ…", "cancelled": "âŒ"}.get(t.get('status'), "â³")
                priority_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(t.get('priority'), "ğŸŸ¡")
                lines.append(f"{status_icon} [{t['id']}] {t['content'][:40]} {priority_icon}")
                if len(t['content']) > 40:
                    lines.append(f"    ...{t['content'][40:]}")
            
            lines.append("â”€" * 50)
            lines.append(f"Total: {len(todos)} tasks ({sum(1 for t in todos if t.get('status') != 'done')} pending)")
            return "\n".join(lines)
            
        elif action == "update":
            if not id:
                return "[Error] 'id' is required for update action"
            
            found = False
            for todo in todos:
                if todo["id"] == id:
                    if content:
                        todo["content"] = content
                    if priority and priority in ["high", "medium", "low"]:
                        todo["priority"] = priority
                    if status and status in ["pending", "in_progress", "done", "cancelled"]:
                        todo["status"] = status
                        if status == "done":
                            todo["completed_at"] = datetime.now().isoformat()
                    todo["updated_at"] = datetime.now().isoformat()
                    found = True
                    break
            
            if not found:
                return f"[Error] Todo with id '{id}' not found."
            
            async with aiofiles.open(todo_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(todos, indent=2, ensure_ascii=False))
            return f"[Success] Updated todo [{id}]"
            
        elif action == "delete":
            if not id:
                return "[Error] 'id' is required for delete action"
            
            original_len = len(todos)
            todos = [t for t in todos if t["id"] != id]
            
            if len(todos) == original_len:
                return f"[Error] Todo with id '{id}' not found."
            
            async with aiofiles.open(todo_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(todos, indent=2, ensure_ascii=False))
            return f"[Success] Deleted todo [{id}]"
            
        elif action == "toggle":
            if not id:
                return "[Error] 'id' is required for toggle action"
            
            for todo in todos:
                if todo["id"] == id:
                    if todo.get("status") == "done":
                        todo["status"] = "pending"
                        todo["completed_at"] = None
                        msg = "marked as pending"
                    else:
                        todo["status"] = "done"
                        todo["completed_at"] = datetime.now().isoformat()
                        msg = "completed"
                    
                    todo["updated_at"] = datetime.now().isoformat()
                    
                    async with aiofiles.open(todo_file, 'w', encoding='utf-8') as f:
                        await f.write(json.dumps(todos, indent=2, ensure_ascii=False))
                    
                    return f"[Success] Todo [{id}] {msg} âœ…"
            
            return f"[Error] Todo with id '{id}' not found."
            
        else:
            return f"[Error] Unknown action: {action}. Use: create, list, update, delete, toggle"
            
    except Exception as e:
        return f"[Error] Todo operation failed: {str(e)}"

# ==================== æœ¬åœ°ç¯å¢ƒå·¥å…·æ³¨å†Œè¡¨ï¼ˆé‡å‘½åç‰ˆï¼‰====================

LOCAL_TOOLS_REGISTRY = {
    "list_files_local": {
        "type": "function",
        "function": {
            "name": "list_files_tool_local",
            "description": "List files and directories in the workspace (local filesystem).",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "The directory path (default: .)"},
                    "show_all": {"type": "boolean", "description": "Show hidden files (default: false)"}
                }
            }
        }
    },
    "read_file_local": {
        "type": "function",
        "function": {
            "name": "read_file_tool_local",
            "description": "Read the contents of a file with line numbers (local filesystem).",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "The path to the file"}
                },
                "required": ["path"]
            }
        }
    },
    "search_files_local": {
        "type": "function",
        "function": {
            "name": "search_files_tool_local",
            "description": "Search for a text pattern recursively in files using grep (local filesystem).",
            "parameters": {
                "type": "object",
                "properties": {
                    "pattern": {"type": "string", "description": "The regex or text to search for"},
                    "path": {"type": "string", "description": "Directory to search in (default: .)"}
                },
                "required": ["pattern"]
            }
        }
    },
    "glob_files_local": {
        "type": "function",
        "function": {
            "name": "glob_files_tool_local",
            "description": "Find files using glob patterns (local filesystem). Much more powerful than list_files for finding specific file types across the project.",
            "parameters": {
                "type": "object",
                "properties": {
                    "pattern": {
                        "type": "string", 
                        "description": "Glob pattern like '**/*.py', 'src/**/*.ts', '*.md'"
                    },
                    "exclude": {
                        "type": "string",
                        "description": "Comma-separated exclusion patterns (default: '**/node_modules/**,**/.git/**')"
                    }
                },
                "required": ["pattern"]
            }
        }
    },
    "edit_file_local": {
        "type": "function",
        "function": {
            "name": "edit_file_tool_local",
            "description": "Create or Overwrite a file with new content (local filesystem).",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "The file path"},
                    "content": {"type": "string", "description": "The full content to write to the file"}
                },
                "required": ["path", "content"]
            }
        }
    },
    "edit_file_patch_local": {
        "type": "function",
        "function": {
            "name": "edit_file_patch_tool_local",
            "description": "Precise string replacement (local filesystem). Finds a specific code block and replaces it, preserving the rest of the file.",
            "parameters": {
                "type": "object",
                "properties": {
                    "path": {"type": "string", "description": "Path to the file to edit"},
                    "old_string": {"type": "string", "description": "The exact code block to replace"},
                    "new_string": {"type": "string", "description": "The new code block to insert"}
                },
                "required": ["path", "old_string", "new_string"]
            }
        }
    },
    "todo_write_local": {
        "type": "function",
        "function": {
            "name": "todo_write_tool_local",
            "description": "Task management system with persistent storage in .party/ai_todos.json (local filesystem).",
            "parameters": {
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "enum": ["create", "list", "update", "delete", "toggle"],
                        "description": "Operation to perform"
                    },
                    "id": {"type": "string", "description": "Task ID"},
                    "content": {"type": "string", "description": "Task description"},
                    "priority": {"type": "string", "enum": ["high", "medium", "low"]},
                    "status": {"type": "string", "enum": ["pending", "in_progress", "done", "cancelled"]}
                },
                "required": ["action"]
            }
        }
    },
    "bash_local": {
        "type": "function",
        "function": {
            "name": "bash_tool_local", 
            "description": "Execute a bash command in the local terminal. Requires 'yolo' permission mode for dangerous operations.",
            "parameters": {
                "type": "object",
                "properties": {
                    "command": {"type": "string", "description": "The bash command"}
                },
                "required": ["command"]
            }
        }
    }
}

def get_local_tools_for_mode(mode: str) -> list:
    """
    æ ¹æ®æƒé™æ¨¡å¼è¿”å›æœ¬åœ°ç¯å¢ƒå·¥å…·å®šä¹‰åˆ—è¡¨
    """
    read_only = [
        LOCAL_TOOLS_REGISTRY["list_files_local"],
        LOCAL_TOOLS_REGISTRY["read_file_local"],
        LOCAL_TOOLS_REGISTRY["search_files_local"],
        LOCAL_TOOLS_REGISTRY["glob_files_local"]
    ]
    
    edit = [
        LOCAL_TOOLS_REGISTRY["edit_file_local"],
        LOCAL_TOOLS_REGISTRY["edit_file_patch_local"]
    ]
    
    todo = [LOCAL_TOOLS_REGISTRY["todo_write_local"]]
    bash = [LOCAL_TOOLS_REGISTRY["bash_local"]]
    
    if mode == "default":
        return read_only
    elif mode == "auto-approve": 
        return read_only + edit + todo
    elif mode == "yolo":
        return read_only + edit + todo + bash
    else:
        return read_only




# ==================== Claude Code & Qwen Code å·¥å…·ï¼ˆåŸæœ‰ï¼‰=====================

cli_info = """è¿™æ˜¯ä¸€ä¸ªäº¤äº’å¼å‘½ä»¤è¡Œå·¥å…·ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·å®Œæˆè½¯ä»¶å·¥ç¨‹ä»»åŠ¡..."""

async def claude_code_async(prompt) -> str | AsyncIterator[str]:
    """Claude Code è°ƒç”¨"""
    settings = await load_settings()
    CLISettings = settings.get("CLISettings", {})
    cwd = CLISettings.get("cc_path")
    ccSettings = settings.get("ccSettings", {})
    
    if not cwd or not cwd.strip():
        return "No working directory is set, please set the working directory first!"
    
    extra_config = {}
    if ccSettings.get("enabled"):
        extra_config = {
            "ANTHROPIC_BASE_URL": ccSettings.get("base_url"),
            "ANTHROPIC_API_KEY": ccSettings.get("api_key"),
            "ANTHROPIC_MODEL": ccSettings.get("model"),
        }
        extra_config = {k: str(v) if v is not None else "" for k, v in extra_config.items()}
        print(f"Using Claude Code with the following settings: {extra_config}")
    
    print(f"Using mode: {ccSettings.get('permissionMode', 'default')}")

    async def _stream() -> AsyncIterator[str]:
        options = ClaudeAgentOptions(
            cwd=cwd,
            continue_conversation=True,
            permission_mode=ccSettings.get("permissionMode", "default"),
            env={**os.environ, **extra_config}
        )
        async for message in query(prompt=prompt, options=options):
            if isinstance(message, AssistantMessage):
                for block in message.content:
                    if isinstance(block, TextBlock):
                        yield block.text

    return _stream()

claude_code_tool = {
    "type": "function",
    "function": {
        "name": "claude_code_async",
        "description": f"ä½ å¯ä»¥å’Œæ§åˆ¶CLIçš„æ™ºèƒ½ä½“Claude Codeè¿›è¡Œäº¤äº’ã€‚{cli_info}",
        "parameters": {
            "type": "object",
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "ä½ æƒ³è®©Claude Codeæ‰§è¡Œçš„æŒ‡ä»¤...",
                }
            },
            "required": ["prompt"],
        },
    },
}

async def qwen_code_async(prompt: str) -> str | AsyncIterator[str]:
    """Qwen Code è°ƒç”¨"""
    settings = await load_settings()
    CLISettings = settings.get("CLISettings", {})
    cwd = CLISettings.get("cc_path")
    qcSettings = settings.get("qcSettings", {})

    if not cwd or not cwd.strip():
        return "No working directory is set, please set the working directory first!"
    
    if not os.path.isdir(cwd):
        return f"The working directory '{cwd}' does not exist!"

    extra_config: dict[str, str] = {}
    if qcSettings.get("enabled"):
        extra_config = {
            "OPENAI_BASE_URL": str(qcSettings.get("base_url") or ""),
            "OPENAI_API_KEY": str(qcSettings.get("api_key") or ""),
            "OPENAI_MODEL": str(qcSettings.get("model") or ""),
        }
    
    approval_mode = str(qcSettings.get("permissionMode", "default"))
    executable = shutil.which("qwen") or "qwen"

    async def _stream() -> AsyncIterator[str]:
        cmd_args = [executable, "-p", prompt, "--approval-mode", approval_mode]
        
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd_args,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=cwd,
                env={**os.environ, **extra_config},
            )
        except FileNotFoundError:
            yield f"[ERROR] System cannot find the executable: {executable}..."
            return
        except Exception as e:
            yield f"[ERROR] Failed to start subprocess: {str(e)}"
            return

        async for out in _merge_streams(
            read_stream(process.stdout),
            read_stream(process.stderr, is_error=True),
        ):
            yield out

        await process.wait()

    return _stream()

qwen_code_tool = {
    "type": "function",
    "function": {
        "name": "qwen_code_async",
        "description": f"ä½ å¯ä»¥å’Œæ§åˆ¶CLIçš„æ™ºèƒ½ä½“Qwen Codeè¿›è¡Œäº¤äº’ã€‚{cli_info}",
        "parameters": {
            "type": "object",
            "properties": {
                "prompt": {
                    "type": "string",
                    "description": "ä½ æƒ³è®©Qwen Codeæ‰§è¡Œçš„æŒ‡ä»¤...",
                }
            },
            "required": ["prompt"],
        },
    },
}

docker_sandbox_tool = {
    "type": "function",
    "function": {
        "name": "docker_sandbox_async",
        "description": "åœ¨éš”ç¦»ä¸”æŒä¹…åŒ–çš„ Docker æ²™ç›’ç¯å¢ƒä¸­æ‰§è¡Œ bash å‘½ä»¤...",
        "parameters": {
            "type": "object",
            "properties": {
                "command": {
                    "type": "string",
                    "description": "è¦æ‰§è¡Œçš„å®Œæ•´ bash å‘½ä»¤...",
                }
            },
            "required": ["command"],
        },
    },
}